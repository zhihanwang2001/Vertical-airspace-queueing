# RP1 Project Cleanup Plan

## Objective
Remove all Chinese content and AI-related traces from the research project while maintaining code functionality and research integrity.

## Scope Summary
- **Total Files**: 989 files (1.4 GB)
- **Files with Chinese Content**: ~161 files
- **Files with AI References**: ~272 files
- **Python Files**: 113 files
- **Markdown Files**: 43 files
- **JSON Files**: 140 files

---

## Phase 1: Documentation Cleanup

### 1.1 Remove Chinese Documentation Files
**Priority: HIGH**

Files to DELETE:
- `/Documentation/guides/Final_Paper_Chinese_Version.md` - Complete Chinese manuscript
- `/Documentation/references/文献引用格式规范.md` - Chinese citation format guide

**Action**: Delete these files entirely as they are Chinese-only versions.

### 1.2 Clean Main Documentation Files
**Priority: HIGH**

Files to EDIT:
- `README.md` - Remove any Chinese text, keep English only
- `/Code/env/README.md` - Check for Chinese comments
- `/Analysis/ANALYSIS_COMPLETE.md` - Remove Chinese content
- `/Analysis/reports/*.md` - Clean all analysis reports

**Action**: Replace Chinese text with English equivalents or remove if redundant.

### 1.3 Remove AI Generation Markers
**Priority: MEDIUM**

Search and remove patterns like:
- "Generated by AI"
- "AI-assisted"
- "Claude generated"
- "GPT-generated"
- Any references to AI tools in comments

---

## Phase 2: Python Code Cleanup

### 2.1 Convert Chinese Comments to English
**Priority: HIGH**

Affected files (~50 Python files with Chinese comments):
- `/Code/analysis_scripts/*.py` - Analysis and plotting scripts
- `/Code/training_scripts/*.py` - Training scripts
- `/Code/algorithms/**/*.py` - Algorithm implementations
- `/Code/env/*.py` - Environment files

**Strategy**:
1. Search for Chinese characters: `[\u4e00-\u9fff]`
2. Translate comments to English
3. Ensure code logic remains unchanged

### 2.2 Remove AI-Related Comments
**Priority: MEDIUM**

Remove comments that reference:
- AI assistance in code generation
- "Auto-generated" markers
- Tool-specific references (Claude, GPT, etc.)

### 2.3 Clean Docstrings
**Priority: LOW**

Ensure all docstrings are:
- In English only
- Professional and neutral
- Free of AI generation markers

---

## Phase 3: Data and Results Cleanup

### 3.1 Clean Text Reports
**Priority: MEDIUM**

Files to clean:
- `/Results/comparison/comparison_report.txt`
- `/Results/generalization/generalization_ranking.txt`
- `/Data/comparison/comparison_report.txt`
- `/Data/generalization/generalization_ranking.txt`

**Action**: Remove Chinese text, keep English analysis only.

### 3.2 Review CSV Files
**Priority: LOW**

Check CSV files for:
- Chinese column headers
- Chinese data entries
- Replace with English equivalents

### 3.3 JSON Files
**Priority: LOW**

JSON files typically contain data, but check for:
- Chinese keys or values in metadata
- AI-related metadata fields

---

## Phase 4: Analysis and Visualization Scripts

### 4.1 Clean Plot Labels and Titles
**Priority: HIGH**

Files to check:
- `/Analysis/visualization/plot_results.py`
- `/Analysis/visualization/plot_results_english.py`
- `/Code/analysis_scripts/plot_*.py` (multiple files)

**Action**:
- Ensure all plot titles, labels, legends are in English
- Remove Chinese text from matplotlib configurations
- Clean up any AI-related annotations

### 4.2 Statistical Analysis Scripts
**Priority: MEDIUM**

Files:
- `/Analysis/statistical_analysis/statistical_tests.py`
- `/Code/analysis_scripts/statistical_power_analysis.py`

**Action**: Remove Chinese comments and ensure English output.

---

## Phase 5: Configuration and Metadata

### 5.1 Git History
**Priority: LOW**

**Note**: Git history will retain Chinese commits. Options:
1. Keep history as-is (recommended for research integrity)
2. Squash commits with English-only messages
3. Start fresh repository (not recommended)

**Recommendation**: Keep git history intact for research provenance.

### 5.2 File Naming
**Priority: HIGH**

Files with Chinese names:
- `/Documentation/references/文献引用格式规范.md`

**Action**: Already identified for deletion in Phase 1.1

### 5.3 Hidden Files and Metadata
**Priority: LOW**

Check:
- `.claude/` directory for AI-related content
- Any hidden configuration files

---

## Phase 6: Verification and Testing

### 6.1 Code Functionality Test
**Priority: CRITICAL**

After cleanup, verify:
1. Environment imports work correctly
2. Training scripts can initialize
3. Analysis scripts can load data
4. No broken imports or references

**Test Commands**:
```bash
# Test environment import
python -c "from Code.env import VerticalQueueEnv"

# Test algorithm imports
python -c "from Code.algorithms.baselines import sb3_a2c_baseline"

# Run a quick training test (1000 steps)
python Code/training_scripts/test_sb3_save.py
```

### 6.2 Documentation Review
**Priority: HIGH**

Verify:
- README.md is clear and professional
- No Chinese text remains
- No AI generation markers
- Research integrity maintained

### 6.3 Final Scan
**Priority: HIGH**

Run final searches:
```bash
# Search for Chinese characters
grep -r "[\u4e00-\u9fff]" .

# Search for AI markers
grep -ri "generated by" .
grep -ri "claude" .
grep -ri "gpt" .
grep -ri "ai-assisted" .
```

---

## Implementation Order

### Stage 1: Critical Cleanup (Do First)
1. Delete Chinese documentation files
2. Clean README.md
3. Convert Chinese comments in core environment files
4. Convert Chinese comments in main training scripts

### Stage 2: Comprehensive Cleanup
5. Clean all Python files for Chinese comments
6. Remove AI-related markers from code
7. Clean analysis and visualization scripts
8. Clean data reports and text files

### Stage 3: Polish and Verify
9. Review all markdown documentation
10. Test code functionality
11. Final scan for remaining issues
12. Update README with clean project description

---

## Estimated Time

- **Phase 1**: 1-2 hours
- **Phase 2**: 3-4 hours (most time-consuming)
- **Phase 3**: 1 hour
- **Phase 4**: 2 hours
- **Phase 5**: 30 minutes
- **Phase 6**: 1 hour

**Total**: 8-10 hours of focused work

---

## Risk Assessment

### Low Risk
- Deleting Chinese-only documentation
- Translating comments (code logic unchanged)
- Removing AI markers from comments

### Medium Risk
- Modifying plot generation scripts (test outputs)
- Cleaning data files (verify data integrity)

### High Risk
- None identified (all changes are non-functional)

---

## Backup Strategy

**CRITICAL**: Before starting cleanup:

```bash
# Create backup
cd /Users/harry./Desktop/EJOR
cp -r RP1 RP1_backup_$(date +%Y%m%d)

# Or create git branch
cd RP1
git checkout -b cleanup-chinese-ai
```

---

## Success Criteria

✅ No Chinese characters in any file
✅ No AI generation markers or references
✅ All code runs without errors
✅ Documentation is professional and clear
✅ Research integrity maintained
✅ Git history preserved (optional)

---

## Notes

- This is a research project, so maintain scientific accuracy
- Keep all experimental data and results intact
- Only modify presentation, not substance
- Document any significant changes in git commits
