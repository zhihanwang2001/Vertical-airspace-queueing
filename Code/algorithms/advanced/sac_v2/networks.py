"""
SAC v2 Neural Networks
SAC v2ç®—æ³•çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬Actorå’ŒCriticç½‘ç»œ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Dict, Any, Optional
from torch.distributions import Normal


class ActorNetwork(nn.Module):
    """SAC Actorç½‘ç»œ - éšæœºç­–ç•¥ç½‘ç»œ"""
    
    def __init__(self,
                 state_dim: int,
                 action_dim: int, 
                 hidden_dim: int = 256,
                 max_action: float = 1.0,
                 log_std_min: float = -20,
                 log_std_max: float = 2):
        super(ActorNetwork, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.max_action = max_action
        self.log_std_min = log_std_min
        self.log_std_max = log_std_max
        
        # å…±äº«ç‰¹å¾å±‚
        self.feature_layers = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU()
        )
        
        # å‡å€¼å’Œå¯¹æ•°æ ‡å‡†å·®è¾“å‡º
        self.mean_layer = nn.Linear(hidden_dim, action_dim)
        self.log_std_layer = nn.Linear(hidden_dim, action_dim)
        
        # æƒé‡åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                # Xavieråˆå§‹åŒ–
                nn.init.xavier_uniform_(module.weight)
                nn.init.constant_(module.bias, 0.0)
        
        # æœ€åä¸€å±‚ç‰¹æ®Šåˆå§‹åŒ–
        nn.init.uniform_(self.mean_layer.weight, -3e-3, 3e-3)
        nn.init.uniform_(self.mean_layer.bias, -3e-3, 3e-3)
        nn.init.uniform_(self.log_std_layer.weight, -3e-3, 3e-3)
        nn.init.uniform_(self.log_std_layer.bias, -3e-3, 3e-3)
    
    def forward(self, state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state: çŠ¶æ€ [batch_size, state_dim]
            
        Returns:
            mean: åŠ¨ä½œå‡å€¼ [batch_size, action_dim]
            log_std: åŠ¨ä½œå¯¹æ•°æ ‡å‡†å·® [batch_size, action_dim]
        """
        features = self.feature_layers(state)
        mean = self.mean_layer(features)
        log_std = self.log_std_layer(features)
        
        # é™åˆ¶å¯¹æ•°æ ‡å‡†å·®èŒƒå›´
        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)
        
        return mean, log_std
    
    def sample_action(self, state: torch.Tensor, deterministic: bool = False) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        é‡‡æ ·åŠ¨ä½œ
        
        Args:
            state: çŠ¶æ€
            deterministic: æ˜¯å¦ç¡®å®šæ€§é‡‡æ ·
            
        Returns:
            action: åŠ¨ä½œ
            log_prob: å¯¹æ•°æ¦‚ç‡
        """
        mean, log_std = self.forward(state)
        
        if deterministic:
            # ç¡®å®šæ€§åŠ¨ä½œ
            action = torch.tanh(mean) * self.max_action
            log_prob = torch.zeros_like(action).sum(dim=-1, keepdim=True)
        else:
            # éšæœºé‡‡æ ·
            std = torch.exp(log_std)
            normal = Normal(mean, std)
            
            # é‡å‚æ•°åŒ–é‡‡æ ·
            x = normal.rsample()  # ä½¿ç”¨rsampleä»¥æ”¯æŒæ¢¯åº¦ä¼ æ’­
            action = torch.tanh(x) * self.max_action
            
            # è®¡ç®—å¯¹æ•°æ¦‚ç‡ï¼ˆè€ƒè™‘tanhå˜æ¢ï¼‰
            log_prob = normal.log_prob(x)
            # ä¿®æ­£tanhå˜æ¢çš„jacobian
            log_prob -= torch.log(self.max_action * (1 - torch.tanh(x).pow(2)) + 1e-6)
            log_prob = log_prob.sum(dim=-1, keepdim=True)
        
        return action, log_prob
    
    def evaluate_action(self, state: torch.Tensor, action: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è¯„ä¼°åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡å’Œç†µ
        
        Args:
            state: çŠ¶æ€
            action: åŠ¨ä½œ
            
        Returns:
            log_prob: å¯¹æ•°æ¦‚ç‡
            entropy: ç†µ
        """
        mean, log_std = self.forward(state)
        std = torch.exp(log_std)
        normal = Normal(mean, std)
        
        # åtanhå˜æ¢
        action_scaled = action / self.max_action
        x = 0.5 * torch.log((1 + action_scaled + 1e-6) / (1 - action_scaled + 1e-6))
        
        # è®¡ç®—å¯¹æ•°æ¦‚ç‡
        log_prob = normal.log_prob(x)
        # ä¿®æ­£tanhå˜æ¢çš„jacobian
        log_prob -= torch.log(self.max_action * (1 - action_scaled.pow(2)) + 1e-6)
        log_prob = log_prob.sum(dim=-1, keepdim=True)
        
        # è®¡ç®—ç†µ
        entropy = normal.entropy().sum(dim=-1, keepdim=True)
        
        return log_prob, entropy


class CriticNetwork(nn.Module):
    """SAC Criticç½‘ç»œ - Qç½‘ç»œ"""
    
    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int = 256):
        super(CriticNetwork, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        
        # Qç½‘ç»œ
        self.q_network = nn.Sequential(
            nn.Linear(state_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
        
        # æƒé‡åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                nn.init.constant_(module.bias, 0.0)
    
    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state: çŠ¶æ€ [batch_size, state_dim]
            action: åŠ¨ä½œ [batch_size, action_dim]
            
        Returns:
            q_value: Qå€¼ [batch_size, 1]
        """
        q_input = torch.cat([state, action], dim=-1)
        q_value = self.q_network(q_input)
        return q_value


class SAC_v2_Networks:
    """SAC v2ç½‘ç»œé›†åˆ"""
    
    def __init__(self,
                 state_dim: int,
                 action_dim: int, 
                 hidden_dim: int = 256,
                 max_action: float = 1.0,
                 device: torch.device = torch.device('cpu')):
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.max_action = max_action
        self.device = device
        
        # Actorç½‘ç»œ
        self.actor = ActorNetwork(
            state_dim, action_dim, hidden_dim, max_action
        ).to(device)
        
        # ä¸¤ä¸ªCriticç½‘ç»œï¼ˆå‡å°‘ä¼°è®¡åå·®ï¼‰
        self.critic1 = CriticNetwork(state_dim, action_dim, hidden_dim).to(device)
        self.critic2 = CriticNetwork(state_dim, action_dim, hidden_dim).to(device)
        
        # ç›®æ ‡Criticç½‘ç»œï¼ˆè½¯æ›´æ–°ï¼‰
        self.target_critic1 = CriticNetwork(state_dim, action_dim, hidden_dim).to(device)
        self.target_critic2 = CriticNetwork(state_dim, action_dim, hidden_dim).to(device)
        
        # åˆå§‹åŒ–ç›®æ ‡ç½‘ç»œ
        self.soft_update_target_networks(tau=1.0)
        
        # è‡ªåŠ¨ç†µè°ƒèŠ‚
        self.target_entropy = -action_dim  # å¯å‘å¼ç›®æ ‡ç†µ
        self.log_alpha = torch.zeros(1, requires_grad=True, device=device)
        
        print(f"ğŸ­ SAC v2 Networks initialized")
        print(f"   State dim: {state_dim}, Action dim: {action_dim}")
        print(f"   Hidden dim: {hidden_dim}, Max action: {max_action}")
        print(f"   Target entropy: {self.target_entropy}")
    
    @property
    def alpha(self):
        """è·å–å½“å‰ç†µç³»æ•°"""
        return self.log_alpha.exp()
    
    def soft_update_target_networks(self, tau: float = 0.005):
        """è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        for target_param, param in zip(self.target_critic1.parameters(), self.critic1.parameters()):
            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)
        
        for target_param, param in zip(self.target_critic2.parameters(), self.critic2.parameters()):
            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)


def create_sac_v2_networks(state_space, action_space, network_config: Dict[str, Any] = None):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºSAC v2ç½‘ç»œ
    
    Args:
        state_space: çŠ¶æ€ç©ºé—´
        action_space: åŠ¨ä½œç©ºé—´
        network_config: ç½‘ç»œé…ç½®
        
    Returns:
        SAC v2ç½‘ç»œé›†åˆ
    """
    default_config = {
        'hidden_dim': 256,
        'max_action': 1.0
    }
    
    if network_config:
        default_config.update(network_config)
    
    # è·å–çŠ¶æ€å’ŒåŠ¨ä½œç»´åº¦
    if len(state_space.shape) == 1:
        state_dim = state_space.shape[0]
    else:
        raise ValueError(f"SAC v2 only supports 1D state space, got {state_space.shape}")
    
    if len(action_space.shape) == 1:
        action_dim = action_space.shape[0]
        max_action = float(action_space.high[0])  # å‡è®¾æ‰€æœ‰ç»´åº¦ç›¸åŒ
    else:
        raise ValueError(f"SAC v2 only supports 1D action space, got {action_space.shape}")
    
    return SAC_v2_Networks(
        state_dim=state_dim,
        action_dim=action_dim,
        hidden_dim=default_config['hidden_dim'],
        max_action=max_action
    )