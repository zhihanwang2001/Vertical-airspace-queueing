"""
TD7 Neural Networks
TD7ç®—æ³•çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬Actorã€Criticå’ŒSALEç¼–ç å™¨
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Dict, Any, Optional


class StateEncoder(nn.Module):
    """SALEçŠ¶æ€ç¼–ç å™¨ - å­¦ä¹ çŠ¶æ€è¡¨ç¤º"""
    
    def __init__(self,
                 state_dim: int,
                 embedding_dim: int = 256,
                 hidden_dim: int = 256):
        super(StateEncoder, self).__init__()
        
        self.state_dim = state_dim
        self.embedding_dim = embedding_dim
        
        # çŠ¶æ€ç¼–ç ç½‘ç»œ
        self.encoder = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, embedding_dim)
        )
        
        # AvgL1Normå½’ä¸€åŒ–ï¼ˆTD7ç‰¹è‰²ï¼‰
        self.normalize = True
        
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.orthogonal_(module.weight, gain=np.sqrt(2))
                nn.init.constant_(module.bias, 0.0)
    
    def forward(self, state: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state: çŠ¶æ€ [batch_size, state_dim]
            
        Returns:
            embedding: çŠ¶æ€åµŒå…¥ [batch_size, embedding_dim]
        """
        embedding = self.encoder(state)
        
        # AvgL1Normå½’ä¸€åŒ–
        if self.normalize:
            # è®¡ç®—L1èŒƒæ•°å¹¶å½’ä¸€åŒ–
            l1_norm = torch.mean(torch.abs(embedding), dim=-1, keepdim=True)
            embedding = embedding / (l1_norm + 1e-8)
        
        return embedding


class TD7_Actor(nn.Module):
    """TD7 Actorç½‘ç»œ"""
    
    def __init__(self,
                 state_dim: int,
                 action_dim: int,
                 embedding_dim: int = 256,
                 hidden_dim: int = 256,
                 max_action: float = 1.0):
        super(TD7_Actor, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.embedding_dim = embedding_dim
        self.max_action = max_action
        
        # ä½¿ç”¨çŠ¶æ€åµŒå…¥ä½œä¸ºè¾“å…¥
        self.policy_network = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim),
            nn.Tanh()
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.orthogonal_(module.weight, gain=np.sqrt(2))
                nn.init.constant_(module.bias, 0.0)
        
        # æœ€åä¸€å±‚å°åˆå§‹åŒ–
        nn.init.uniform_(self.policy_network[-2].weight, -3e-3, 3e-3)
        nn.init.uniform_(self.policy_network[-2].bias, -3e-3, 3e-3)
    
    def forward(self, state_embedding: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state_embedding: çŠ¶æ€åµŒå…¥ [batch_size, embedding_dim]
            
        Returns:
            action: åŠ¨ä½œ [batch_size, action_dim]
        """
        action = self.policy_network(state_embedding)
        return action * self.max_action


class TD7_Critic(nn.Module):
    """TD7 Criticç½‘ç»œ - åŒQç½‘ç»œ"""
    
    def __init__(self,
                 state_dim: int,
                 action_dim: int,
                 embedding_dim: int = 256,
                 hidden_dim: int = 256):
        super(TD7_Critic, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.embedding_dim = embedding_dim
        
        # Qç½‘ç»œ1 - ä½¿ç”¨çŠ¶æ€åµŒå…¥+åŠ¨ä½œ
        self.q1_network = nn.Sequential(
            nn.Linear(embedding_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
        
        # Qç½‘ç»œ2 - åŒQç½‘ç»œå‡å°‘ä¼°è®¡åå·®
        self.q2_network = nn.Sequential(
            nn.Linear(embedding_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.orthogonal_(module.weight, gain=np.sqrt(2))
                nn.init.constant_(module.bias, 0.0)
    
    def forward(self, 
                state_embedding: torch.Tensor, 
                action: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state_embedding: çŠ¶æ€åµŒå…¥ [batch_size, embedding_dim]
            action: åŠ¨ä½œ [batch_size, action_dim]
            
        Returns:
            q1_value: Q1å€¼ [batch_size, 1]
            q2_value: Q2å€¼ [batch_size, 1]
        """
        q_input = torch.cat([state_embedding, action], dim=-1)
        
        q1_value = self.q1_network(q_input)
        q2_value = self.q2_network(q_input)
        
        return q1_value, q2_value
    
    def q1(self, state_embedding: torch.Tensor, action: torch.Tensor) -> torch.Tensor:
        """åªè¿”å›Q1å€¼ï¼ˆç”¨äºActoræ›´æ–°ï¼‰"""
        q_input = torch.cat([state_embedding, action], dim=-1)
        return self.q1_network(q_input)


class TD7_Networks:
    """TD7ç½‘ç»œé›†åˆ"""
    
    def __init__(self,
                 state_dim: int,
                 action_dim: int,
                 embedding_dim: int = 256,
                 hidden_dim: int = 256,
                 max_action: float = 1.0,
                 device: torch.device = torch.device('cpu')):
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.embedding_dim = embedding_dim
        self.max_action = max_action
        self.device = device
        
        # çŠ¶æ€ç¼–ç å™¨
        self.state_encoder = StateEncoder(
            state_dim, embedding_dim, hidden_dim
        ).to(device)
        
        # Actorç½‘ç»œ
        self.actor = TD7_Actor(
            state_dim, action_dim, embedding_dim, hidden_dim, max_action
        ).to(device)
        
        # Criticç½‘ç»œ
        self.critic = TD7_Critic(
            state_dim, action_dim, embedding_dim, hidden_dim
        ).to(device)
        
        # ç›®æ ‡ç½‘ç»œ
        self.target_state_encoder = StateEncoder(
            state_dim, embedding_dim, hidden_dim
        ).to(device)
        
        self.target_actor = TD7_Actor(
            state_dim, action_dim, embedding_dim, hidden_dim, max_action
        ).to(device)
        
        self.target_critic = TD7_Critic(
            state_dim, action_dim, embedding_dim, hidden_dim
        ).to(device)
        
        # åˆå§‹åŒ–ç›®æ ‡ç½‘ç»œ
        self.soft_update_target_networks(tau=1.0)
        
        print(f"ğŸ¯ TD7 Networks initialized")
        print(f"   State dim: {state_dim}, Action dim: {action_dim}")
        print(f"   Embedding dim: {embedding_dim}, Hidden dim: {hidden_dim}")
        print(f"   Max action: {max_action}")
    
    def soft_update_target_networks(self, tau: float = 0.005):
        """è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        # æ›´æ–°çŠ¶æ€ç¼–ç å™¨
        for target_param, param in zip(self.target_state_encoder.parameters(), 
                                     self.state_encoder.parameters()):
            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)
        
        # æ›´æ–°Actor
        for target_param, param in zip(self.target_actor.parameters(), 
                                     self.actor.parameters()):
            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)
        
        # æ›´æ–°Critic
        for target_param, param in zip(self.target_critic.parameters(), 
                                     self.critic.parameters()):
            target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)


def create_td7_networks(state_space, action_space, network_config: Dict[str, Any] = None):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºTD7ç½‘ç»œ
    
    Args:
        state_space: çŠ¶æ€ç©ºé—´
        action_space: åŠ¨ä½œç©ºé—´
        network_config: ç½‘ç»œé…ç½®
        
    Returns:
        TD7ç½‘ç»œé›†åˆ
    """
    default_config = {
        'embedding_dim': 256,
        'hidden_dim': 256,
        'max_action': 1.0
    }
    
    if network_config:
        default_config.update(network_config)
    
    # è·å–çŠ¶æ€å’ŒåŠ¨ä½œç»´åº¦
    if len(state_space.shape) == 1:
        state_dim = state_space.shape[0]
    else:
        raise ValueError(f"TD7 only supports 1D state space, got {state_space.shape}")
    
    if len(action_space.shape) == 1:
        action_dim = action_space.shape[0]
        max_action = float(action_space.high[0])  # å‡è®¾æ‰€æœ‰ç»´åº¦ç›¸åŒ
    else:
        raise ValueError(f"TD7 only supports 1D action space, got {action_space.shape}")
    
    return TD7_Networks(
        state_dim=state_dim,
        action_dim=action_dim,
        embedding_dim=default_config['embedding_dim'],
        hidden_dim=default_config['hidden_dim'],
        max_action=max_action
    )