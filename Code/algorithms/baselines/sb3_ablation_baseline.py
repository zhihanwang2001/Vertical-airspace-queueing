"""
æ¶ˆèå®éªŒåŸºçº¿ç®—æ³•
Ablation Study Baseline Algorithm

ä¸ºæ¶ˆèå®éªŒåˆ›å»ºçš„ç‰¹æ®ŠPPOåŸºçº¿ï¼Œæ”¯æŒï¼š
1. åŠ¨æ€é…ç½®ä¿®æ”¹ï¼ˆé«˜å±‚ä¼˜å…ˆã€å®¹é‡ç»“æ„ã€è½¬ç§»æœºåˆ¶ç­‰ï¼‰
2. å•ç›®æ ‡vså¤šç›®æ ‡å¥–åŠ±å‡½æ•°åˆ‡æ¢  
3. ç»„ä»¶çº§åˆ«çš„å¼€å…³æ§åˆ¶
4. ä¸å®Œæ•´ç³»ç»Ÿå…¬å¹³å¯¹æ¯”çš„å®éªŒè®¾ç½®

åŸºäºsb3_ppo_baseline.pyï¼Œæ·»åŠ æ¶ˆèå®éªŒç‰¹å®šåŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import math
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, BaseCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv
import torch

from env.drl_optimized_env_fixed import DRLOptimizedQueueEnvFixed
from .space_utils import SB3DictWrapper
from ablation_configs import AblationConfigs, AblationEnvironmentFactory


class AblationLearningRateLogger(BaseCallback):
    """æ¶ˆèå®éªŒå­¦ä¹ ç‡è®°å½•å™¨"""
    
    def __init__(self, initial_lr: float = 3e-4, min_lr: float = 1e-6, 
                 ablation_type: str = "full_system", verbose: int = 1):
        super().__init__(verbose)
        self.initial_lr = initial_lr
        self.min_lr = min_lr
        self.ablation_type = ablation_type
        
    def _on_step(self) -> bool:
        """è®°å½•å½“å‰å­¦ä¹ ç‡å’Œæ¶ˆèå®éªŒä¿¡æ¯åˆ°TensorBoard"""
        current_lr = self.model.policy.optimizer.param_groups[0]['lr']
        progress_remaining = getattr(self.model, '_current_progress_remaining', 1.0)
        progress = 1.0 - progress_remaining
        
        # è®°å½•åŸºç¡€å­¦ä¹ ç‡ä¿¡æ¯
        self.logger.record("train/learning_rate", current_lr)
        self.logger.record("train/lr_progress", progress)
        self.logger.record("train/lr_decay_ratio", current_lr / self.initial_lr)
        
        # è®°å½•æ¶ˆèå®éªŒç±»å‹
        self.logger.record("ablation/experiment_type", self.ablation_type)
        
        # å®šæœŸæ‰“å°
        if self.num_timesteps % 10000 == 0 and self.verbose > 0:
            print(f"[{self.ablation_type}] Step {self.num_timesteps:6,}: LR={current_lr:.6f}")
        
        return True


def apply_ablation_config_to_env(env, ablation_config):
    """ç›´æ¥åº”ç”¨æ¶ˆèé…ç½®åˆ°ç¯å¢ƒï¼Œä¸ä½¿ç”¨åŒ…è£…å™¨"""
    
    # 1. ä¿®æ”¹åˆ°è¾¾æƒé‡ï¼ˆæ— é«˜å±‚ä¼˜å…ˆå®éªŒï¼‰
    env.arrival_weights = np.array(ablation_config.arrival_weights, dtype=np.float32)
    
    # 2. ä¿®æ”¹å®¹é‡é…ç½®ï¼ˆä¼ ç»Ÿé‡‘å­—å¡”å®éªŒï¼‰
    env.capacities = np.array(ablation_config.layer_capacities, dtype=np.int32)
    
    # 3. ä¿®æ”¹æœåŠ¡ç‡
    env.base_service_rates = np.array(ablation_config.layer_service_rates, dtype=np.float32)
    
    # 4. å¤„ç†å¥–åŠ±å‡½æ•°ä¿®æ”¹ï¼ˆå•ç›®æ ‡å®éªŒï¼‰
    if hasattr(ablation_config, '_reward_type') and ablation_config._reward_type == 'throughput_only':
        env._single_objective_mode = True
        
    # 5. å¤„ç†è½¬ç§»æœºåˆ¶ï¼ˆæ— è½¬ç§»å®éªŒï¼‰
    if hasattr(ablation_config, '_transfer_enabled') and not ablation_config._transfer_enabled:
        env._transfer_disabled = True
        
    ablation_type = getattr(ablation_config, '_ablation_type', 'unknown')
    print(f"âœ… åº”ç”¨æ¶ˆèä¿®æ”¹: {ablation_type}")
    if hasattr(ablation_config, '_removed_component'):
        print(f"   ç§»é™¤ç»„ä»¶: {ablation_config._removed_component}")
    
    return env


class AblationEnvironmentWrapper:
    """æ¶ˆèå®éªŒç¯å¢ƒåŒ…è£…å™¨ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
    
    def __init__(self, base_env, ablation_config):
        self.base_env = base_env
        self.ablation_config = ablation_config
        self.ablation_type = getattr(ablation_config, '_ablation_type', 'full_system')
        
        # åº”ç”¨æ¶ˆèä¿®æ”¹
        self._apply_ablation_modifications()
    
    def _apply_ablation_modifications(self):
        """åº”ç”¨æ¶ˆèå®éªŒçš„ä¿®æ”¹"""
        
        # 1. ä¿®æ”¹åˆ°è¾¾æƒé‡ï¼ˆæ— é«˜å±‚ä¼˜å…ˆå®éªŒï¼‰
        self.base_env.arrival_weights = np.array(self.ablation_config.arrival_weights, dtype=np.float32)
        
        # 2. ä¿®æ”¹å®¹é‡é…ç½®ï¼ˆä¼ ç»Ÿé‡‘å­—å¡”å®éªŒï¼‰
        self.base_env.capacities = np.array(self.ablation_config.layer_capacities, dtype=np.int32)
        
        # 3. ä¿®æ”¹æœåŠ¡ç‡
        self.base_env.base_service_rates = np.array(self.ablation_config.layer_service_rates, dtype=np.float32)
        
        # 4. å¤„ç†å¥–åŠ±å‡½æ•°ä¿®æ”¹ï¼ˆå•ç›®æ ‡å®éªŒï¼‰
        if hasattr(self.ablation_config, '_reward_type') and self.ablation_config._reward_type == 'throughput_only':
            self.base_env._single_objective_mode = True
            
        # 5. å¤„ç†è½¬ç§»æœºåˆ¶ï¼ˆæ— è½¬ç§»å®éªŒï¼‰
        if hasattr(self.ablation_config, '_transfer_enabled') and not self.ablation_config._transfer_enabled:
            self.base_env._transfer_disabled = True
            
        print(f"âœ… åº”ç”¨æ¶ˆèä¿®æ”¹: {self.ablation_type}")
        if hasattr(self.ablation_config, '_removed_component'):
            print(f"   ç§»é™¤ç»„ä»¶: {self.ablation_config._removed_component}")
    
    def __getattr__(self, name):
        """ä»£ç†åˆ°åŸºç¡€ç¯å¢ƒ"""
        return getattr(self.base_env, name)


class SB3AblationBaseline:
    """æ¶ˆèå®éªŒPPOåŸºçº¿ç®—æ³•"""
    
    def __init__(self, ablation_type: str = "full_system", config=None):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒåŸºçº¿
        
        Args:
            ablation_type: æ¶ˆèå®éªŒç±»å‹
                - "full_system": å®Œæ•´ç³»ç»Ÿï¼ˆå¯¹ç…§ç»„ï¼‰
                - "no_high_priority": æ— é«˜å±‚ä¼˜å…ˆ
                - "single_objective": å•ç›®æ ‡ä¼˜åŒ–
                - "traditional_pyramid": ä¼ ç»Ÿé‡‘å­—å¡”
                - "no_transfer": æ— è½¬ç§»æœºåˆ¶
            config: é¢å¤–çš„PPOé…ç½®å‚æ•°
        """
        
        self.ablation_type = ablation_type
        
        # è·å–æ¶ˆèé…ç½®
        all_configs = AblationConfigs.get_all_ablation_configs()
        if ablation_type not in all_configs:
            raise ValueError(f"æœªçŸ¥çš„æ¶ˆèç±»å‹: {ablation_type}")
        
        self.ablation_config = all_configs[ablation_type]
        
        # PPOé…ç½®
        default_config = {
            'learning_rate': 3e-4,
            'n_steps': 2048,
            'batch_size': 64,
            'n_epochs': 10,
            'gamma': 0.99,
            'gae_lambda': 0.95,
            'clip_range': 0.2,
            'clip_range_vf': None,
            'normalize_advantage': True,
            'ent_coef': 0.0,
            'vf_coef': 0.5,
            'max_grad_norm': 0.5,
            'target_kl': None,
            'tensorboard_log': "./tensorboard_logs/",
            'verbose': 1,
            'seed': 42
        }
        
        if config:
            default_config.update(config)
        
        self.config = default_config
        self.model = None
        self.env = None
        
        print(f"ğŸ§ª åˆå§‹åŒ–æ¶ˆèå®éªŒ: {ablation_type}")
        if hasattr(self.ablation_config, '_removed_component'):
            print(f"   ç§»é™¤ç»„ä»¶: {self.ablation_config._removed_component}")
        
    def setup_env(self):
        """è®¾ç½®æ¶ˆèå®éªŒç¯å¢ƒ"""
        base_env = DRLOptimizedQueueEnvFixed()
        
        # ç›´æ¥åº”ç”¨æ¶ˆèé…ç½®
        apply_ablation_config_to_env(base_env, self.ablation_config)
        
        # åŒ…è£…ç¯å¢ƒ
        wrapped_env = SB3DictWrapper(base_env)
        self.env = Monitor(wrapped_env, filename=None)
        
        # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
        self.vec_env = DummyVecEnv([lambda: self.env])
        
        print(f"âœ… æ¶ˆèç¯å¢ƒè®¾ç½®å®Œæˆ: {self.ablation_type}")
        return self.env
    
    def create_model(self):
        """åˆ›å»ºæ¶ˆèå®éªŒPPOæ¨¡å‹"""
        if self.env is None:
            self.setup_env()
        
        # ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ï¼ˆä¸å®Œæ•´ç³»ç»Ÿä¿æŒä¸€è‡´ï¼‰
        def cosine_annealing_schedule(progress_remaining):
            initial_lr = self.config['learning_rate']
            min_lr = self.config.get('min_lr', 1e-6)
            progress = 1.0 - progress_remaining
            cosine_factor = 0.5 * (1 + math.cos(math.pi * progress))
            current_lr = min_lr + (initial_lr - min_lr) * cosine_factor
            return current_lr
        
        # åˆ›å»ºPPOæ¨¡å‹
        self.model = PPO(
            "MlpPolicy",
            self.vec_env,
            learning_rate=cosine_annealing_schedule,
            n_steps=self.config['n_steps'],
            batch_size=self.config['batch_size'],
            n_epochs=self.config['n_epochs'],
            gamma=self.config['gamma'],
            gae_lambda=self.config['gae_lambda'],
            clip_range=self.config['clip_range'],
            clip_range_vf=self.config['clip_range_vf'],
            normalize_advantage=self.config['normalize_advantage'],
            ent_coef=self.config['ent_coef'],
            vf_coef=self.config['vf_coef'],
            max_grad_norm=self.config['max_grad_norm'],
            target_kl=self.config['target_kl'],
            tensorboard_log=self.config['tensorboard_log'],
            verbose=self.config['verbose'],
            seed=self.config['seed'],
            device='auto'
        )
        
        print(f"âœ… æ¶ˆèPPOæ¨¡å‹åˆ›å»ºå®Œæˆ: {self.ablation_type}")
        return self.model
    
    def train(self, total_timesteps, eval_freq=10000, save_freq=50000):
        """è®­ç»ƒæ¶ˆèå®éªŒæ¨¡å‹ - ç®€åŒ–ç‰ˆæœ¬é¿å…pickleé”™è¯¯"""
        if self.model is None:
            self.create_model()
        
        # å¼€å§‹è®­ç»ƒ
        print(f"ğŸš€ å¼€å§‹æ¶ˆèå®éªŒè®­ç»ƒ: {self.ablation_type}")
        print(f"   è®­ç»ƒæ­¥æ•°: {total_timesteps:,}")
        if hasattr(self.ablation_config, '_removed_component'):
            print(f"   ç§»é™¤ç»„ä»¶: {self.ablation_config._removed_component}")
        
        # ä½¿ç”¨ç®€åŒ–çš„è®­ç»ƒï¼Œä¸ä½¿ç”¨å¤æ‚çš„callback
        self.model.learn(
            total_timesteps=total_timesteps,
            log_interval=10
        )
        
        print(f"âœ… æ¶ˆèå®éªŒè®­ç»ƒå®Œæˆ: {self.ablation_type}")
        
        return self.model
    
    def evaluate(self, n_episodes=10):
        """è¯„ä¼°æ¶ˆèå®éªŒæ¨¡å‹æ€§èƒ½ - ç®€åŒ–ç‰ˆæœ¬"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train()")
        
        print(f"ğŸ“Š è¯„ä¼°æ¶ˆèå®éªŒ: {self.ablation_type}")
        
        episode_rewards = []
        
        for episode in range(n_episodes):
            obs = self.vec_env.reset()
            total_reward = 0
            done = False
            step_count = 0
            
            while not done and step_count < 1000:  # é™åˆ¶æœ€å¤§æ­¥æ•°
                action, _ = self.model.predict(obs, deterministic=True)
                obs, reward, done, info = self.vec_env.step(action)
                total_reward += reward[0]
                step_count += 1
            
            episode_rewards.append(total_reward)
            
            if episode % 5 == 0:
                print(f"   Episode {episode+1}/{n_episodes}: Reward={total_reward:.2f}")
        
        # è®¡ç®—ç»Ÿè®¡é‡
        mean_reward = np.mean(episode_rewards)
        std_reward = np.std(episode_rewards)
        
        results = {
            'ablation_type': self.ablation_type,
            'mean_reward': mean_reward,
            'std_reward': std_reward,
            'n_episodes': n_episodes,
            'removed_component': getattr(self.ablation_config, '_removed_component', 'None')
        }
        
        print(f"ğŸ“ˆ {self.ablation_type} è¯„ä¼°ç»“æœ:")
        print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
        
        return results


# æ¶ˆèå®éªŒç®¡ç†å™¨
class AblationExperimentManager:
    """æ¶ˆèå®éªŒç®¡ç†å™¨"""
    
    def __init__(self, total_timesteps=100000):
        self.total_timesteps = total_timesteps
        self.results = {}
        
    def run_all_ablation_experiments(self):
        """è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ"""
        ablation_types = [
            'full_system',
            'no_high_priority', 
            'single_objective',
            'traditional_pyramid',
            'no_transfer'
        ]
        
        print(f"ğŸ§ª å¼€å§‹å®Œæ•´æ¶ˆèå®éªŒç ”ç©¶")
        print(f"   å®éªŒæ•°é‡: {len(ablation_types)}")
        print(f"   æ¯ä¸ªå®éªŒè®­ç»ƒæ­¥æ•°: {self.total_timesteps:,}")
        print("=" * 60)
        
        for i, ablation_type in enumerate(ablation_types, 1):
            print(f"\nğŸ¯ æ‰§è¡Œå®éªŒ {i}/{len(ablation_types)}: {ablation_type}")
            print("-" * 40)
            
            try:
                # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
                baseline = SB3AblationBaseline(ablation_type)
                baseline.train(self.total_timesteps)
                
                # è¯„ä¼°æ€§èƒ½
                results = baseline.evaluate(n_episodes=20)
                self.results[ablation_type] = results
                
                print(f"âœ… {ablation_type} å®éªŒå®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {ablation_type} å®éªŒå¤±è´¥: {str(e)}")
                self.results[ablation_type] = {'error': str(e)}
        
        print(f"\nğŸ‰ æ¶ˆèå®éªŒç ”ç©¶å®Œæˆ!")
        self._print_comparison_results()
        
        return self.results
    
    def _print_comparison_results(self):
        """æ‰“å°å¯¹æ¯”ç»“æœ"""
        print(f"\nğŸ“Š æ¶ˆèå®éªŒå¯¹æ¯”ç»“æœ:")
        print("=" * 80)
        print(f"{'å®éªŒç±»å‹':<20} {'å¹³å‡å¥–åŠ±':<15} {'æ ‡å‡†å·®':<10} {'æ€§èƒ½ä¸‹é™':<10} {'ç§»é™¤ç»„ä»¶'}")
        print("-" * 80)
        
        full_system_reward = self.results.get('full_system', {}).get('mean_reward', 0)
        
        for ablation_type, result in self.results.items():
            if 'error' in result:
                print(f"{ablation_type:<20} {'ERROR':<15} {'-':<10} {'-':<10} {'-'}")
                continue
                
            mean_reward = result.get('mean_reward', 0)
            std_reward = result.get('std_reward', 0)
            removed_component = result.get('removed_component', 'None')
            
            if ablation_type == 'full_system':
                performance_drop = '0.0%'
            else:
                if full_system_reward > 0:
                    drop_percent = (full_system_reward - mean_reward) / full_system_reward * 100
                    performance_drop = f"{drop_percent:.1f}%"
                else:
                    performance_drop = 'N/A'
            
            print(f"{ablation_type:<20} {mean_reward:<15.2f} {std_reward:<10.2f} "
                  f"{performance_drop:<10} {removed_component}")
        
        print("-" * 80)
    
    def save_results(self, filepath="ablation_results.json"):
        """ä¿å­˜å®éªŒç»“æœ"""
        import json
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2)
        print(f"ğŸ’¾ å®éªŒç»“æœä¿å­˜è‡³: {filepath}")


# æµ‹è¯•å’Œç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    print("ğŸ§ª æ¶ˆèå®éªŒåŸºçº¿æµ‹è¯•")
    
    # æµ‹è¯•å•ä¸ªæ¶ˆèå®éªŒ
    print("\n1. æµ‹è¯•å•ä¸ªæ¶ˆèå®éªŒ...")
    baseline = SB3AblationBaseline("no_high_priority")
    
    # å¿«é€Ÿæµ‹è¯•è®­ç»ƒ
    print("   å¿«é€Ÿè®­ç»ƒæµ‹è¯•...")
    baseline.train(total_timesteps=1000)  # å¿«é€Ÿæµ‹è¯•
    
    # è¯„ä¼°
    print("   è¯„ä¼°æµ‹è¯•...")
    results = baseline.evaluate(n_episodes=3)
    
    print(f"âœ… å•ä¸ªæ¶ˆèå®éªŒæµ‹è¯•å®Œæˆ!")
    print(f"   ç»“æœ: {results}")