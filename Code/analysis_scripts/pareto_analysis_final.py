"""
å‚ç›´åˆ†å±‚é˜Ÿåˆ—ç³»ç»Ÿçš„å¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†åˆ†æå®ç°ï¼ˆæœ€ç»ˆä¿®æ­£ç‰ˆï¼‰
Pareto Optimal Set Analysis for Vertical Stratified Queuing System (Final Fixed Version)
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
import seaborn as sns
from scipy.optimize import minimize, differential_evolution
from scipy.spatial.distance import cdist
from sklearn.decomposition import PCA
from typing import List, Tuple, Dict, Optional
import pandas as pd
from itertools import combinations
import warnings
import time
warnings.filterwarnings('ignore')

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from env.drl_optimized_env_fixed import DRLOptimizedQueueEnvFixed


class ParetoAnalyzer:
    """å¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†åˆ†æå™¨ï¼ˆæœ€ç»ˆä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, env):
        """
        Args:
            env: å‚ç›´åˆ†å±‚é˜Ÿåˆ—ç¯å¢ƒå®ä¾‹
        """
        self.env = env
        self.objective_names = [
            'Throughput', 'Balance', 'Efficiency',
            'Transfer', 'Stability', 'Anti-Penalty'
        ]
        self.n_objectives = len(self.objective_names)
        
        # å­˜å‚¨è¯„ä¼°ç»“æœ
        self.solutions = []
        self.objective_values = []
        self.pareto_indices = []
        self.pareto_front = []
        
        print(f"ParetoAnalyzer initialized with {self.n_objectives} objectives")
    
    def evaluate_solution(self, policy_params: Dict, n_episodes: int = 5) -> np.ndarray:
        """
        è¯„ä¼°å•ä¸ªè§£çš„å¤šç›®æ ‡æ€§èƒ½
        
        Args:
            policy_params: ç­–ç•¥å‚æ•°å­—å…¸
            n_episodes: è¯„ä¼°è½®æ•°
            
        Returns:
            6ç»´ç›®æ ‡å‘é‡
        """
        objective_values = np.zeros(self.n_objectives)
        
        for episode in range(n_episodes):
            obs, _ = self.env.reset()
            episode_objectives = np.zeros(self.n_objectives)
            steps = 0
            
            while steps < 200:  # æœ€å¤§æ­¥æ•°é™åˆ¶
                # æ ¹æ®ç­–ç•¥å‚æ•°ç”ŸæˆåŠ¨ä½œ
                action = self._policy_to_action(obs, policy_params)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_obs, reward, terminated, truncated, info = self.env.step(action)

                # æå–å¤šç›®æ ‡å¥–åŠ±åˆ†é‡ï¼ˆä½¿ç”¨stepåçš„è§‚æµ‹å’Œinfoï¼‰
                objectives = self._extract_objectives(next_obs, action, reward, info)
                episode_objectives += objectives
                
                obs = next_obs
                steps += 1
                
                if terminated or truncated:
                    break
            
            # ä¸¥æ ¼è¯„ä¼°ï¼šç¡®ä¿ç­–ç•¥çš„æŒç»­æ€§å’Œç¨³å®šæ€§
            if steps >= 50:  # æé«˜æœ€å°æ­¥æ•°è¦æ±‚åˆ°50æ­¥
                # æ­£å¸¸çš„æŒ‰æ­¥æ•°å¹³å‡åŒ–
                objective_values += episode_objectives / max(steps, 1)
            elif steps >= 20:
                # ä¸­ç­‰é•¿åº¦episodeç»™äºˆéƒ¨åˆ†åˆ†æ•°ï¼ˆæƒ©ç½šä¸å¤Ÿç¨³å®šçš„ç­–ç•¥ï¼‰
                penalty_factor = steps / 50.0  # çº¿æ€§æƒ©ç½š
                objective_values += (episode_objectives / max(steps, 1)) * penalty_factor
            else:
                # çŸ­æœŸepisodeï¼ˆ<20æ­¥ï¼‰è§†ä¸ºæ— æ•ˆç­–ç•¥
                objective_values += np.zeros(self.n_objectives)
        
        return objective_values / n_episodes
    
    def _policy_to_action(self, obs, policy_params: Dict) -> Dict:
        """å°†ç­–ç•¥å‚æ•°è½¬æ¢ä¸ºç¯å¢ƒåŠ¨ä½œ"""
        # æå–è§‚å¯Ÿä¿¡æ¯
        if isinstance(obs, dict):
            utilization = obs.get('utilization_rates', np.ones(5) * 0.5)
            queue_lengths = obs.get('queue_lengths', np.ones(5))
        elif isinstance(obs, np.ndarray):
            queue_lengths = obs[:5] if len(obs) >= 5 else np.ones(5)
            utilization = obs[5:10] if len(obs) >= 10 else np.ones(5) * 0.5
        else:
            queue_lengths = np.ones(5)
            utilization = np.ones(5) * 0.5
        
        # åŸºäºç­–ç•¥å‚æ•°ç”ŸæˆåŠ¨ä½œ
        action = {
            'service_intensities': np.array([
                policy_params.get('base_service', 1.0) + 
                policy_params.get('adaptation', 0.1) * (util - 0.5)
                for util in utilization
            ], dtype=np.float32).clip(0.1, 2.0),
            
            'arrival_multiplier': np.array([policy_params.get('arrival_factor', 1.0)], dtype=np.float32).clip(0.5, 5.0),
            
            'emergency_transfers': (utilization > policy_params.get('transfer_threshold', 0.8)).astype(np.int8)
        }
        
        return action
    
    def _extract_objectives(self, obs, action: Dict, reward: float, info: Dict) -> np.ndarray:
        """
        ä»ç¯å¢ƒstepè¿”å›ä¸­æå–å¤šç›®æ ‡å‘é‡ï¼ˆä¿®å¤ç‰ˆ-ä½¿ç”¨ç¯å¢ƒå¥–åŠ±ç»„ä»¶ï¼‰

        æ ¸å¿ƒä¿®å¤ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒæä¾›çš„å¥–åŠ±ç»„ä»¶åˆ†è§£ï¼ˆreward_componentsï¼‰
        2. é¿å…é‡å¤è®¡ç®—å’Œæ—¶åºä¸ä¸€è‡´é—®é¢˜
        3. ç¡®ä¿ä¸ç¯å¢ƒå¥–åŠ±å‡½æ•°å®Œå…¨ä¸€è‡´

        Returns:
            6ç»´ç›®æ ‡å‘é‡ï¼Œæ‰€æœ‰ç›®æ ‡éƒ½æ˜¯è¶Šå¤§è¶Šå¥½
        """

        # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨ç¯å¢ƒæä¾›çš„å¥–åŠ±ç»„ä»¶ï¼ˆæœ€å‡†ç¡®ï¼‰
        if 'reward_components' in info:
            components = info['reward_components']

            throughput_obj = components['throughput']
            balance_obj = components['balance']
            efficiency_obj = components['efficiency']
            transfer_obj = components['transfer']
            stability_obj = components['stability']

            # å°†è´Ÿæƒ©ç½šè½¬æ¢ä¸ºæ­£å‘ç›®æ ‡
            penalty_obj = -(components['congestion'] + components['instability'])

            return np.array([throughput_obj, balance_obj, efficiency_obj, transfer_obj, stability_obj, penalty_obj])

        # æ–¹æ³•2ï¼šå¤‡ç”¨è®¡ç®—ï¼ˆå¦‚æœç¯å¢ƒæœªæä¾›reward_componentsï¼‰
        print("è­¦å‘Šï¼šç¯å¢ƒæœªæä¾›reward_componentsï¼Œä½¿ç”¨å¤‡ç”¨è®¡ç®—æ–¹æ³•")

        # ä»infoä¸­æå–ç»Ÿè®¡æ•°æ®
        service_counts = np.array(info.get('service_counts', np.zeros(5)))
        transfer_counts = np.array(info.get('transfer_counts', np.zeros(5)))

        # ä»obsä¸­æå–é˜Ÿåˆ—çŠ¶æ€
        if isinstance(obs, dict):
            queue_lengths = obs.get('queue_lengths', np.zeros(5))
        elif isinstance(obs, np.ndarray) and len(obs) >= 5:
            queue_lengths = obs[:5]
        else:
            queue_lengths = np.zeros(5)

        # ç¯å¢ƒå›ºå®šå‚æ•°
        capacities = np.array([8, 6, 4, 3, 2])

        # 1. ååé‡ç›®æ ‡
        throughput_obj = 10.0 * np.sum(service_counts)

        # 2. è´Ÿè½½å‡è¡¡ç›®æ ‡ï¼ˆåŸºå°¼ç³»æ•°ï¼‰
        utilization_rates = queue_lengths / (capacities + 1e-8)
        if np.sum(utilization_rates) > 1e-6:
            sorted_util = np.sort(utilization_rates)
            n = len(sorted_util)
            gini = (2 * np.sum((np.arange(n) + 1) * sorted_util)) / (n * np.sum(sorted_util)) - (n + 1) / n
            balance_obj = 5.0 * (1.0 - gini)
        else:
            balance_obj = 5.0

        # 3. æ•ˆç‡ç›®æ ‡
        service_total = np.sum(service_counts)
        base_energy = 1.0 + np.sum(action['service_intensities']) + action['arrival_multiplier'][0] * 0.5 + np.sum(action['emergency_transfers']) * 0.2
        if base_energy > 1e-6:
            efficiency_obj = 3.0 * service_total / base_energy
        else:
            efficiency_obj = 0.0

        # 4. è½¬ç§»æ•ˆç‡ç›®æ ‡
        transfer_obj = 0.0
        for i in range(4):
            if transfer_counts[i] > 0:
                upper_pressure = queue_lengths[i] / (capacities[i] + 1e-8)
                lower_util = queue_lengths[i+1] / (capacities[i+1] + 1e-8)
                if upper_pressure > lower_util:
                    transfer_obj += 2.0 * transfer_counts[i]

        # 5. ç¨³å®šæ€§ç›®æ ‡
        stability_obj = info.get('stability_score', 0.0)

        # 6. åæƒ©ç½šç›®æ ‡
        congestion_levels = np.maximum(0, (queue_lengths - 0.8 * capacities) / capacities)
        congestion_penalty = -20.0 * np.sum(congestion_levels)

        # ä½¿ç”¨infoä¸­çš„current_service_rateså’Œcurrent_arrival_rateè®¡ç®—ä¸ç¨³å®šæƒ©ç½š
        if 'current_service_rates' in info and 'current_arrival_rate' in info:
            current_service_rates = np.array(info['current_service_rates'])
            current_arrival_rate = info['current_arrival_rate']
            arrival_weights = np.array([0.3, 0.25, 0.2, 0.15, 0.1])
            current_arrivals = current_arrival_rate * arrival_weights
            load_rates = current_arrivals / np.maximum(current_service_rates, 1e-6)
            instability_levels = np.maximum(0, load_rates - 0.95)
            instability_penalty = -15.0 * np.sum(instability_levels)
        else:
            instability_penalty = 0.0

        penalty_obj = -(congestion_penalty + instability_penalty)

        return np.array([throughput_obj, balance_obj, efficiency_obj, transfer_obj, stability_obj, penalty_obj])
    
    def generate_random_solutions(self, n_solutions: int = 10000) -> None:
        """ç”Ÿæˆéšæœºè§£é›†è¿›è¡Œå¸•ç´¯æ‰˜åˆ†æ"""
        print(f"Generating {n_solutions} random solutions...")
        start_time = time.time()
        
        self.solutions = []
        self.objective_values = []
        
        for i in range(n_solutions):
            if i % 500 == 0:
                elapsed = time.time() - start_time
                eta = elapsed * (n_solutions - i) / (i + 1) if i > 0 else 0
                print(f"  Progress: {i}/{n_solutions} ({i/n_solutions*100:.1f}%) - ETA: {eta/60:.1f}min")
            
            # ä¿®å¤ï¼šç”Ÿæˆç‰©ç†åˆç†çš„ç­–ç•¥å‚æ•°ç»„åˆ
            # é¿å…æç«¯çš„åˆ°è¾¾ç‡+æœåŠ¡ç‡ç»„åˆå¯¼è‡´ç³»ç»Ÿè¿‡è½½

            arrival_factor = np.random.uniform(0.5, 3.0)  # é™åˆ¶åˆ°è¾¾å€æ•°æœ€å¤§3x

            # æ ¹æ®åˆ°è¾¾å€æ•°è°ƒæ•´æœåŠ¡èƒ½åŠ›èŒƒå›´ï¼Œç¡®ä¿ç³»ç»Ÿå¯è¿è¡Œ
            if arrival_factor > 2.0:
                # é«˜åˆ°è¾¾ç‡æ—¶ï¼Œéœ€è¦è¾ƒé«˜çš„åŸºç¡€æœåŠ¡èƒ½åŠ›
                base_service_range = (0.8, 1.5)
                adaptation_range = (0.1, 0.4)
            elif arrival_factor > 1.5:
                # ä¸­ç­‰åˆ°è¾¾ç‡æ—¶ï¼Œä¸­ç­‰æœåŠ¡èƒ½åŠ›
                base_service_range = (0.5, 1.3)
                adaptation_range = (0.0, 0.6)
            else:
                # ä½åˆ°è¾¾ç‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¹¿æ³›çš„æœåŠ¡èƒ½åŠ›
                base_service_range = (0.3, 1.2)
                adaptation_range = (0.0, 0.8)

            policy_params = {
                'base_service': np.random.uniform(*base_service_range),
                'adaptation': np.random.uniform(*adaptation_range),
                'arrival_factor': arrival_factor,
                'transfer_threshold': np.random.uniform(0.4, 0.9)  # æ›´åˆç†çš„è½¬ç§»é˜ˆå€¼
            }
            
            # è¯„ä¼°è§£
            objectives = self.evaluate_solution(policy_params, n_episodes=5)
            
            self.solutions.append(policy_params)
            self.objective_values.append(objectives)
        
        self.objective_values = np.array(self.objective_values)
        elapsed = time.time() - start_time
        print(f"Generated {len(self.solutions)} solutions in {elapsed/60:.1f} minutes")
    
    def find_pareto_front_efficient(self) -> None:
        """é«˜æ•ˆçš„å¸•ç´¯æ‰˜å‰æ²¿è¯†åˆ«ç®—æ³•ï¼ˆNon-dominated Sortingï¼‰+ å¯è¡Œæ€§è¿‡æ»¤"""
        print(f"Finding Pareto front among {len(self.objective_values)} solutions...")
        start_time = time.time()

        n_solutions = len(self.objective_values)

        # ğŸ”§ ä¿®å¤1: å…ˆè¿‡æ»¤æ‰ä¸å¯è¡Œè§£ï¼ˆStability=0çš„ç³»ç»Ÿå´©æºƒè§£ï¼‰
        STABILITY_THRESHOLD = 0.5  # ç¨³å®šæ€§æœ€ä½é˜ˆå€¼
        feasible_mask = self.objective_values[:, 4] > STABILITY_THRESHOLD  # Stabilityæ˜¯ç¬¬5ä¸ªç›®æ ‡

        feasible_indices = np.where(feasible_mask)[0]
        print(f"  Filtering feasible solutions: {len(feasible_indices)}/{n_solutions} are stable")

        if len(feasible_indices) == 0:
            print("  âš ï¸  No feasible solutions found! Using all solutions...")
            feasible_indices = np.arange(n_solutions)

        feasible_objectives = self.objective_values[feasible_indices]
        n_feasible = len(feasible_indices)

        domination_count = np.zeros(n_feasible)  # è¢«æ”¯é…æ¬¡æ•°
        dominated_solutions = [[] for _ in range(n_feasible)]  # æ”¯é…çš„è§£åˆ—è¡¨

        # è®¡ç®—æ”¯é…å…³ç³»ï¼ˆä»…åœ¨å¯è¡Œè§£ä¸­ï¼‰
        for i in range(n_feasible):
            if i % 1000 == 0:
                print(f"  Processing solution {i}/{n_feasible}")

            for j in range(i + 1, n_feasible):
                # æ£€æŸ¥iæ˜¯å¦æ”¯é…j
                i_dominates_j = (np.all(feasible_objectives[i] >= feasible_objectives[j]) and
                               np.any(feasible_objectives[i] > feasible_objectives[j]))

                # æ£€æŸ¥jæ˜¯å¦æ”¯é…i
                j_dominates_i = (np.all(feasible_objectives[j] >= feasible_objectives[i]) and
                               np.any(feasible_objectives[j] > feasible_objectives[i]))

                if i_dominates_j:
                    dominated_solutions[i].append(j)
                    domination_count[j] += 1
                elif j_dominates_i:
                    dominated_solutions[j].append(i)
                    domination_count[i] += 1

        # æ‰¾åˆ°éæ”¯é…è§£ï¼ˆè¢«æ”¯é…æ¬¡æ•°ä¸º0ï¼‰
        pareto_mask = domination_count == 0
        local_pareto_indices = np.where(pareto_mask)[0]

        # æ˜ å°„å›åŸå§‹ç´¢å¼•
        self.pareto_indices = feasible_indices[local_pareto_indices]
        self.pareto_front = self.objective_values[self.pareto_indices]

        elapsed = time.time() - start_time
        print(f"Found {len(self.pareto_indices)} Pareto optimal solutions in {elapsed:.1f} seconds")
        print(f"  Pareto ratio: {len(self.pareto_indices)/n_solutions*100:.2f}%")
    
    def find_pareto_front(self) -> None:
        """å¸•ç´¯æ‰˜å‰æ²¿è¯†åˆ«ï¼ˆè°ƒç”¨é«˜æ•ˆç‰ˆæœ¬ï¼‰"""
        self.find_pareto_front_efficient()
    
    def find_knee_points_improved(self) -> List[int]:
        """
        æ”¹è¿›çš„è†ç‚¹æ£€æµ‹ç®—æ³•ï¼ˆåŸºäºç¨€ç–æ€§å’Œtrade-offåˆ†æï¼‰

        è†ç‚¹å®šä¹‰ï¼šå¸•ç´¯æ‰˜å‰æ²¿ä¸Šæœ€å…·ä»£è¡¨æ€§çš„è§£ï¼Œæ»¡è¶³ï¼š
        1. åˆ°ç†æƒ³ç‚¹è·ç¦»è¾ƒè¿‘ï¼ˆé«˜è´¨é‡ï¼‰
        2. åœ¨å‰æ²¿ä¸Šåˆ†å¸ƒç¨€ç–ï¼ˆä»£è¡¨æ€§å¼ºï¼‰
        3. ç›®æ ‡ä¹‹é—´trade-offåˆç†
        """
        if len(self.pareto_front) < 3:
            return list(range(len(self.pareto_front)))

        print("Finding knee points using improved method...")

        # å›ºå®šè†ç‚¹æ•°é‡ï¼ˆé¿å…é˜ˆå€¼æ–¹æ³•çš„ä¸ç¨³å®šæ€§ï¼‰
        n_pareto = len(self.pareto_front)
        target_knees = max(5, min(15, n_pareto // 20))  # 5-15ä¸ªï¼Œçº¦å 5%

        print(f"  Target knee points: {target_knees} (from {n_pareto} Pareto solutions)")

        # å½’ä¸€åŒ–å¸•ç´¯æ‰˜å‰æ²¿
        ideal_point = np.max(self.pareto_front, axis=0)
        nadir_point = np.min(self.pareto_front, axis=0)
        range_vector = np.maximum(ideal_point - nadir_point, 1e-8)
        normalized_front = (self.pareto_front - nadir_point) / range_vector

        # æ–¹æ³•1ï¼šè®¡ç®—åˆ°ç†æƒ³ç‚¹çš„è·ç¦»ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        ideal_distances = np.linalg.norm(normalized_front - 1.0, axis=1)

        # æ–¹æ³•2ï¼šè®¡ç®—ç¨€ç–æ€§å¾—åˆ†ï¼ˆä½¿ç”¨kè¿‘é‚»è·ç¦»ï¼‰
        # è·ç¦»æœ€è¿‘çš„kä¸ªé‚»å±…çš„å¹³å‡è·ç¦»ï¼ˆè¶Šå¤§è¯´æ˜è¶Šç¨€ç–/ä»£è¡¨æ€§è¶Šå¼ºï¼‰
        k = min(10, n_pareto // 10)
        distances_matrix = cdist(normalized_front, normalized_front, metric='euclidean')
        np.fill_diagonal(distances_matrix, np.inf)  # æ’é™¤è‡ªå·±

        sparsity_scores = np.zeros(n_pareto)
        for i in range(n_pareto):
            # æ‰¾æœ€è¿‘çš„kä¸ªé‚»å±…çš„å¹³å‡è·ç¦»
            nearest_k_distances = np.partition(distances_matrix[i], k)[:k]
            sparsity_scores[i] = np.mean(nearest_k_distances)

        # æ–¹æ³•3ï¼šç›®æ ‡å‡è¡¡æ€§ï¼ˆé¿å…æç«¯è§£ï¼‰
        # ä½¿ç”¨å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰ï¼šstd/meanï¼Œè¶Šå°è¯´æ˜è¶Šå‡è¡¡
        uniformity_scores = np.zeros(n_pareto)
        for i in range(n_pareto):
            point = normalized_front[i]
            mean_val = np.mean(point)
            if mean_val > 1e-6:
                cv = np.std(point) / mean_val
                uniformity_scores[i] = 1.0 / (1.0 + cv)  # è½¬æ¢ä¸ºå¾—åˆ†ï¼ˆè¶Šå¤§è¶Šå‡è¡¡ï¼‰
            else:
                uniformity_scores[i] = 0.0

        # ç»¼åˆå¾—åˆ†ï¼ˆå¤šå‡†åˆ™å†³ç­–ï¼‰
        # å½’ä¸€åŒ–å„é¡¹å¾—åˆ†åˆ°[0,1]
        quality_score = 1.0 - (ideal_distances - ideal_distances.min()) / (ideal_distances.max() - ideal_distances.min() + 1e-8)
        diversity_score = (sparsity_scores - sparsity_scores.min()) / (sparsity_scores.max() - sparsity_scores.min() + 1e-8)
        balance_score = uniformity_scores

        # åŠ æƒç»¼åˆï¼ˆè´¨é‡40%ï¼Œå¤šæ ·æ€§40%ï¼Œå‡è¡¡æ€§20%ï¼‰
        total_scores = quality_score * 0.4 + diversity_score * 0.4 + balance_score * 0.2

        # ç›´æ¥é€‰æ‹©å¾—åˆ†æœ€é«˜çš„target_kneesä¸ªç‚¹
        top_k_indices = np.argsort(total_scores)[-target_knees:]

        # æ˜ å°„å›åŸå§‹solutionsç´¢å¼•
        knee_indices = [self.pareto_indices[i] for i in top_k_indices]

        # è°ƒè¯•ä¿¡æ¯
        print(f"  Quality scores range: [{quality_score.min():.3f}, {quality_score.max():.3f}]")
        print(f"  Diversity scores range: [{diversity_score.min():.3f}, {diversity_score.max():.3f}]")
        print(f"  Balance scores range: [{balance_score.min():.3f}, {balance_score.max():.3f}]")
        print(f"  Final knee points: {len(knee_indices)}")

        return knee_indices
    
    def analyze_objective_conflicts(self) -> Dict:
        """åˆ†æç›®æ ‡å†²çª"""
        if len(self.pareto_front) == 0:
            self.find_pareto_front()
        
        # è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿ä¸Šçš„ç›¸å…³ç³»æ•°çŸ©é˜µ
        corr_matrix = np.corrcoef(self.pareto_front.T)
        
        # æå–å†²çªå…³ç³»ï¼ˆè´Ÿç›¸å…³ï¼‰
        conflicts = {}
        for i in range(self.n_objectives):
            for j in range(i+1, self.n_objectives):
                correlation = corr_matrix[i, j]
                if abs(correlation) > 0.1:  # ç›¸å…³æ€§é˜ˆå€¼ï¼ˆåŒ…æ‹¬æ­£è´Ÿï¼‰
                    name1 = self.objective_names[i]
                    name2 = self.objective_names[j]
                    conflicts[f"{name1} vs {name2}"] = correlation  # ä¿ç•™ç¬¦å·
        
        return conflicts
    
    def plot_pareto_analysis_clean(self, save_path: str = "./pareto_analysis_complete.png") -> None:
        """ç”Ÿæˆæ¸…æ™°çš„å¸•ç´¯æ‰˜åˆ†æå¯è§†åŒ–"""
        if len(self.pareto_front) == 0:
            self.find_pareto_front()
        
        knee_indices = self.find_knee_points_improved()
        
        # åˆ›å»ºä¸‰ä¸ªä¸»è¦å›¾ï¼šæ•£ç‚¹å›¾çŸ©é˜µã€3Då›¾ã€å†²çªçŸ©é˜µ
        
        # 1. å…³é”®ç›®æ ‡å¯¹çš„æ•£ç‚¹å›¾ (2x3å¸ƒå±€)
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # é€‰æ‹©æœ€é‡è¦çš„6ä¸ªç›®æ ‡å¯¹
        important_pairs = [
            (0, 1),  # Throughput vs Balance
            (0, 2),  # Throughput vs Efficiency
            (0, 4),  # Throughput vs Stability
            (1, 2),  # Balance vs Efficiency
            (2, 4),  # Efficiency vs Stability
            (1, 4)   # Balance vs Stability
        ]
        
        for idx, (i, j) in enumerate(important_pairs):
            ax = axes[idx]
            
            # æ‰€æœ‰è§£
            ax.scatter(self.objective_values[:, j], self.objective_values[:, i], 
                      alpha=0.3, s=1, color='lightblue', label='All solutions')
            
            # å¸•ç´¯æ‰˜å‰æ²¿
            ax.scatter(self.pareto_front[:, j], self.pareto_front[:, i], 
                      alpha=0.8, s=15, color='red', label='Pareto front')
            
            # è†ç‚¹
            if knee_indices:
                knee_objectives = self.objective_values[knee_indices]
                ax.scatter(knee_objectives[:, j], knee_objectives[:, i], 
                          alpha=1.0, s=40, color='gold', marker='*', 
                          label='Knee points', edgecolors='black', linewidth=0.5)
            
            ax.set_xlabel(self.objective_names[j], fontsize=12)
            ax.set_ylabel(self.objective_names[i], fontsize=12)
            ax.set_title(f'{self.objective_names[i]} vs {self.objective_names[j]}', fontsize=12)
            
            if idx == 0:
                ax.legend()
        
        plt.suptitle('Pareto Analysis: Key Objective Pairs', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ç›®æ ‡å†²çªçŸ©é˜µ
        corr_matrix = np.corrcoef(self.pareto_front.T)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, 
                   xticklabels=self.objective_names, yticklabels=self.objective_names,
                   ax=ax, vmin=-1, vmax=1, fmt='.3f')
        ax.set_title('Objective Conflicts Matrix (Red = Conflict)', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(save_path.replace('.png', '_conflicts.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. 3Då¸•ç´¯æ‰˜å‰æ²¿ï¼ˆå‰3ä¸ªæœ€é‡è¦ç›®æ ‡ï¼‰
        fig = plt.figure(figsize=(12, 10))
        ax = fig.add_subplot(111, projection='3d')
        
        # æ‰€æœ‰è§£ï¼ˆé‡‡æ ·ä»¥æé«˜æ€§èƒ½ï¼‰
        n_sample = min(1000, len(self.objective_values))
        sample_idx = np.random.choice(len(self.objective_values), n_sample, replace=False)
        
        ax.scatter(self.objective_values[sample_idx, 0], 
                  self.objective_values[sample_idx, 1], 
                  self.objective_values[sample_idx, 2],
                  alpha=0.3, s=1, color='lightblue', label='All solutions')
        
        # å¸•ç´¯æ‰˜å‰æ²¿
        ax.scatter(self.pareto_front[:, 0], self.pareto_front[:, 1], self.pareto_front[:, 2],
                  alpha=0.8, s=20, color='red', label='Pareto front')
        
        # è†ç‚¹
        if knee_indices:
            knee_objectives = self.objective_values[knee_indices]
            ax.scatter(knee_objectives[:, 0], knee_objectives[:, 1], knee_objectives[:, 2],
                      alpha=1.0, s=50, color='gold', marker='*', label='Knee points',
                      edgecolors='black', linewidth=1)
        
        ax.set_xlabel(self.objective_names[0])
        ax.set_ylabel(self.objective_names[1])
        ax.set_zlabel(self.objective_names[2])
        ax.set_title('3D Pareto Front Visualization')
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(save_path.replace('.png', '_3d.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("Clean Pareto analysis plots saved")
    
    def generate_report(self, save_path: str = "./pareto_analysis_report.txt") -> None:
        """ç”Ÿæˆè¯¦ç»†çš„å¸•ç´¯æ‰˜åˆ†ææŠ¥å‘Š"""
        if len(self.pareto_front) == 0:
            self.find_pareto_front()

        conflicts = self.analyze_objective_conflicts()
        knee_indices = self.find_knee_points_improved()
        hypervolume = self.compute_hypervolume()

        # ğŸ”§ ä¿®å¤4: æŠ¥å‘Šä¸­æ·»åŠ å¯è¡Œæ€§æ£€æŸ¥
        unstable_count = np.sum(self.objective_values[:, 4] < 0.5)
        unstable_in_pareto = np.sum(self.pareto_front[:, 4] < 0.5)

        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("å‚ç›´åˆ†å±‚é˜Ÿåˆ—ç³»ç»Ÿå¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")

            f.write(f"æ€»è§£æ•°: {len(self.objective_values)}\n")
            f.write(f"ä¸ç¨³å®šè§£æ•° (Stability<0.5): {unstable_count} ({unstable_count/len(self.objective_values)*100:.1f}%)\n")
            f.write(f"å¸•ç´¯æ‰˜æœ€ä¼˜è§£æ•°: {len(self.pareto_front)}\n")
            f.write(f"å¸•ç´¯æ‰˜ä¸­ä¸ç¨³å®šè§£: {unstable_in_pareto}\n")
            f.write(f"å¸•ç´¯æ‰˜æ¯”ä¾‹: {len(self.pareto_front)/len(self.objective_values)*100:.2f}%\n")
            f.write(f"è¶…ä½“ç§¯æŒ‡æ ‡: {hypervolume:.4f}\n")
            f.write(f"è†ç‚¹æ•°é‡: {len(knee_indices)} ({len(knee_indices)/len(self.pareto_front)*100:.1f}%)\n\n")
            
            f.write("ç›®æ ‡ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write("-"*40 + "\n")
            for i, name in enumerate(self.objective_names):
                all_values = self.objective_values[:, i]
                pareto_values = self.pareto_front[:, i]
                
                f.write(f"{name}:\n")
                f.write(f"  å…¨ä½“è§£: {np.mean(all_values):.3f} Â± {np.std(all_values):.3f}\n")
                f.write(f"  å¸•ç´¯æ‰˜è§£: {np.mean(pareto_values):.3f} Â± {np.std(pareto_values):.3f}\n")
                f.write(f"  èŒƒå›´: [{np.min(pareto_values):.3f}, {np.max(pareto_values):.3f}]\n\n")
            
            f.write("ä¸»è¦ç›®æ ‡å…³ç³»:\n")
            f.write("-"*40 + "\n")
            # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åºï¼Œæ˜¾ç¤ºæœ€å¼ºçš„å…³ç³»ï¼ˆæ­£è´Ÿéƒ½æ˜¾ç¤ºï¼‰
            for conflict_pair, strength in sorted(conflicts.items(), key=lambda x: abs(x[1]), reverse=True):
                f.write(f"{conflict_pair}: {strength:.3f}\n")
            
            if knee_indices:
                f.write(f"\nè†ç‚¹è§£è¯¦æƒ…:\n")
                f.write("-"*40 + "\n")
                for i, idx in enumerate(knee_indices):
                    f.write(f"è†ç‚¹ {i+1}:\n")
                    for j, name in enumerate(self.objective_names):
                        f.write(f"  {name}: {self.objective_values[idx, j]:.3f}\n")
                    f.write("\n")
        
        print(f"Report saved to: {save_path}")
    
    def compute_hypervolume(self, reference_point: Optional[np.ndarray] = None) -> float:
        """è®¡ç®—è¶…ä½“ç§¯æŒ‡æ ‡"""
        if len(self.pareto_front) == 0:
            return 0.0
        
        if reference_point is None:
            # ä½¿ç”¨æœ€å°å€¼ä½œä¸ºå‚è€ƒç‚¹
            reference_point = np.min(self.objective_values, axis=0) - 0.1
        
        # ç®€åŒ–çš„è¶…ä½“ç§¯è®¡ç®—
        hypervolume = 0.0
        for point in self.pareto_front:
            volume = np.prod(np.maximum(0, point - reference_point))
            if volume > 0:
                hypervolume += volume
        
        return hypervolume


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„å¸•ç´¯æ‰˜åˆ†æï¼ˆæœ€ç»ˆç‰ˆï¼‰"""
    print("Starting Pareto Optimal Set Analysis for Vertical Stratified Queuing System (Enhanced Version)")
    print("=" * 80)
    
    # åˆ›å»ºç¯å¢ƒ
    env = DRLOptimizedQueueEnvFixed()
    
    # éªŒè¯ç¯å¢ƒé…ç½®
    print(f"âœ… Environment Configuration:")
    print(f"   Layers: {env.n_layers}")
    print(f"   Heights: {env.heights}")
    print(f"   Capacities: {env.capacities}")
    print(f"   Service rates: {env.base_service_rates}")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ParetoAnalyzer(env)
    
    # ç”Ÿæˆè§£é›† - å¢åŠ åˆ°10000ä¸ªç‚¹
    print("\n1. Generating random solutions...")
    analyzer.generate_random_solutions(n_solutions=10000)
    
    # è¯†åˆ«å¸•ç´¯æ‰˜å‰æ²¿
    print("\n2. Finding Pareto front...")
    analyzer.find_pareto_front()
    
    # åˆ†æç›®æ ‡å†²çª
    print("\n3. Analyzing objective conflicts...")
    conflicts = analyzer.analyze_objective_conflicts()
    print("Main correlations:")
    for conflict, strength in sorted(conflicts.items(), key=lambda x: abs(x[1]), reverse=True)[:3]:
        print(f"  {conflict}: {strength:.3f}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\n4. Generating visualizations...")
    analyzer.plot_pareto_analysis_clean("./pareto_analysis_complete.png")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n5. Generating report...")
    analyzer.generate_report("./pareto_analysis_report.txt")
    
    print("\n" + "=" * 80)
    print("Pareto analysis completed!")
    print("Check the following files:")
    print("  - pareto_analysis_complete.png: Key objective pairs")
    print("  - pareto_analysis_complete_conflicts.png: Conflict matrix")
    print("  - pareto_analysis_complete_3d.png: 3D Pareto front")
    print("  - pareto_analysis_report.txt: Detailed analysis report")


if __name__ == "__main__":
    main()