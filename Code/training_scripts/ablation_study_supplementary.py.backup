"""
è¡¥å……å®éªŒï¼šéªŒè¯çŠ¶æ€ç©ºé—´å¤§å°å‡è®¾
Supplementary Experiments: Verify State Space Size Hypothesis

æ–°å¢é…ç½®ï¼š
- capacity_4x5: [4,4,4,4,4] total=20
- capacity_6x5: [6,6,6,6,6] total=30

éªŒè¯å‡è®¾ï¼šå®¹é‡è¶Šå¤§ â†’ çŠ¶æ€ç©ºé—´è¶Šå¤§ â†’ TD7è®­ç»ƒè¶Šå›°éš¾
"""

import sys
import os
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import gymnasium as gym
import numpy as np
import json
import time
import argparse
from datetime import datetime
from stable_baselines3 import A2C, PPO

from env.config import VerticalQueueConfig
from env.configurable_env_wrapper import ConfigurableEnvWrapper
from env.drl_wrapper_fixed import DictToBoxActionWrapperFixed, ObservationWrapperFixed


def create_config(config_type='capacity_4x5', high_load_multiplier=10.0):
    """åˆ›å»ºé…ç½® - æ–°å¢4x5å’Œ6x5"""
    config = VerticalQueueConfig()

    # è®¾ç½®å®¹é‡
    if config_type == 'capacity_4x5':
        config.layer_capacities = [4, 4, 4, 4, 4]  # æ€»20
    elif config_type == 'capacity_6x5':
        config.layer_capacities = [6, 6, 6, 6, 6]  # æ€»30
    else:
        raise ValueError(f"Unknown config type: {config_type}")

    # å›ºå®šçœŸå®UAMæµé‡æ¨¡å¼
    config.arrival_weights = [0.3, 0.25, 0.2, 0.15, 0.1]

    # è®¡ç®—åˆ°è¾¾ç‡
    total_capacity = sum(config.layer_capacities)
    avg_service_rate = np.mean(config.layer_service_rates)
    base_rate_v3 = 0.75 * total_capacity * avg_service_rate / 5
    config.base_arrival_rate = base_rate_v3 * high_load_multiplier

    # è®¡ç®—æ¯å±‚çš„ç†è®ºè´Ÿè½½
    layer_loads = []
    for i, (w, c) in enumerate(zip(config.arrival_weights, config.layer_capacities)):
        layer_arrival = config.base_arrival_rate * w
        actual_service_rate = config.layer_service_rates[i]
        layer_load = layer_arrival / (c * actual_service_rate)
        layer_loads.append(layer_load)

    print(f"\n{'='*80}")
    print(f"é…ç½®: {config_type}")
    print(f"å®¹é‡: {config.layer_capacities} (æ€»è®¡: {total_capacity})")
    print(f"åˆ°è¾¾æƒé‡: {config.arrival_weights}")
    print(f"æ€»åˆ°è¾¾ç‡: {config.base_arrival_rate:.2f} (v3çš„{high_load_multiplier:.1f}å€)")
    print(f"\nå„å±‚ç†è®ºè´Ÿè½½ (Ï = Î»/(Î¼Â·c)):")
    for i, load in enumerate(layer_loads):
        mu = config.layer_service_rates[i]
        status = "ğŸ”´è¿‡è½½!" if load >= 1.0 else "ğŸŸ¡ä¸´ç•Œ" if load > 0.8 else "ğŸŸ¢æ­£å¸¸"
        print(f"  Layer {i} (å®¹é‡{config.layer_capacities[i]}, Î¼={mu:.1f}): {load*100:.1f}% {status}")
    print(f"å¹³å‡è´Ÿè½½: {np.mean(layer_loads)*100:.1f}%")
    print(f"{'='*80}\n")

    return config


def create_wrapped_env(config):
    """åˆ›å»ºåŒ…è£…åçš„ç¯å¢ƒ"""
    base_env = ConfigurableEnvWrapper(config=config)
    dict_to_box_env = DictToBoxActionWrapperFixed(base_env)
    wrapped_env = ObservationWrapperFixed(dict_to_box_env)
    return wrapped_env


def train_and_evaluate(algorithm='A2C', config_type='capacity_4x5',
                       timesteps=100000, eval_episodes=50, high_load_multiplier=10.0):
    """è®­ç»ƒå’Œè¯„ä¼°"""

    print(f"\n{'='*80}")
    print(f"å®éªŒ: {algorithm} + {config_type}")
    print(f"è¯„ä¼°è½®æ¬¡: {eval_episodes}")
    print(f"{'='*80}\n")

    config = create_config(config_type, high_load_multiplier)
    env = create_wrapped_env(config)

    save_dir = Path(project_root) / 'Results' / 'ablation_study_supplementary_10x' / config_type
    save_dir.mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    # åˆ›å»ºæ¨¡å‹
    if algorithm == 'A2C':
        model = A2C('MlpPolicy', env, verbose=1, device='cuda')
    elif algorithm == 'PPO':
        model = PPO('MlpPolicy', env, verbose=1, device='cuda')
    else:
        raise ValueError(f"Unknown algorithm: {algorithm}")

    print(f"\nå¼€å§‹è®­ç»ƒ{algorithm}...")
    model.learn(total_timesteps=timesteps)

    training_time = time.time() - start_time
    print(f"è®­ç»ƒå®Œæˆï¼ç”¨æ—¶ï¼š{training_time/60:.2f}åˆ†é’Ÿ\n")

    # è¯„ä¼°
    print(f"å¼€å§‹è¯„ä¼° ({eval_episodes} episodes)...")
    eval_env = create_wrapped_env(config)

    rewards = []
    episode_lengths = []
    crashes = 0
    completions = 0

    for ep in range(eval_episodes):
        obs, _ = eval_env.reset()
        episode_reward = 0
        episode_length = 0
        terminated = False

        while True:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, truncated, info = eval_env.step(action)
            episode_reward += reward
            episode_length += 1

            if done:
                terminated = True
                break
            if truncated:
                break

        rewards.append(episode_reward)
        episode_lengths.append(episode_length)

        if terminated:
            crashes += 1
        else:
            completions += 1

        if (ep + 1) % 10 == 0:
            print(f"  è¯„ä¼°è¿›åº¦: {ep+1}/{eval_episodes}")

    # ç»Ÿè®¡ç»“æœ
    crash_rate = crashes / eval_episodes
    completion_rate = completions / eval_episodes

    results = {
        'algorithm': algorithm,
        'config': config_type,
        'mean_reward': float(np.mean(rewards)),
        'std_reward': float(np.std(rewards)),
        'crash_rate': float(crash_rate),
        'completion_rate': float(completion_rate),
        'mean_episode_length': float(np.mean(episode_lengths)),
        'training_time_minutes': float(training_time / 60),
        'eval_episodes': eval_episodes
    }

    # ä¿å­˜ç»“æœ
    results_file = save_dir / f'{algorithm}_results.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\n{'='*80}")
    print(f"è¯„ä¼°ç»“æœ:")
    print(f"  å¹³å‡å¥–åŠ±: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
    print(f"  {'ğŸ”´' if crash_rate > 0 else 'âœ…'} å´©æºƒç‡: {crash_rate*100:.1f}% ({crashes}/{eval_episodes})")
    print(f"  âœ… å®Œæˆç‡: {completion_rate*100:.1f}% ({completions}/{eval_episodes})")
    print(f"  å¹³å‡å›åˆé•¿åº¦: {results['mean_episode_length']:.1f}")
    print(f"  è®­ç»ƒæ—¶é—´: {results['training_time_minutes']:.2f}åˆ†é’Ÿ")
    print(f"  ç»“æœå·²ä¿å­˜è‡³: {results_file}")
    print(f"{'='*80}\n")

    return results


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è¡¥å……å®éªŒï¼šéªŒè¯çŠ¶æ€ç©ºé—´å¤§å°å‡è®¾')
    parser.add_argument('--algorithm', type=str, required=True, choices=['A2C', 'PPO'],
                       help='ç®—æ³•: A2C or PPO')
    parser.add_argument('--config', type=str, required=True, choices=['capacity_4x5', 'capacity_6x5'],
                       help='é…ç½®: capacity_4x5 or capacity_6x5')
    parser.add_argument('--timesteps', type=int, default=100000,
                       help='è®­ç»ƒæ­¥æ•° (default: 100000)')
    parser.add_argument('--eval-episodes', type=int, default=50,
                       help='è¯„ä¼°è½®æ¬¡ (default: 50)')
    parser.add_argument('--high-load-multiplier', type=float, default=10.0,
                       help='é«˜è´Ÿè½½å€æ•° (default: 10.0)')

    args = parser.parse_args()

    train_and_evaluate(
        algorithm=args.algorithm,
        config_type=args.config,
        timesteps=args.timesteps,
        eval_episodes=args.eval_episodes,
        high_load_multiplier=args.high_load_multiplier
    )
