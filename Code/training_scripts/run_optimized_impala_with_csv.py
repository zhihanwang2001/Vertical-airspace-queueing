"""
Run Optimized IMPALA with CSV Logging (Compatible with result_excel format)
ä½¿ç”¨CSVæ—¥å¿—è¿è¡Œä¼˜åŒ–çš„IMPALAç®—æ³•ï¼Œå…¼å®¹result_excelæ–‡ä»¶æ ¼å¼

è¿™ä¸ªè„šæœ¬ä¸“é—¨ä¸ºå…¼å®¹ç°æœ‰çš„ç»“æœæ ¼å¼è€Œåˆ›å»ºï¼Œä¼šç”Ÿæˆä¸å…¶ä»–ç®—æ³•ç›¸åŒæ ¼å¼çš„CSVæ–‡ä»¶
"""

import argparse
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import time
import csv
from algorithms.advanced.impala.impala_optimized import OptimizedIMPALABaseline


class CSVTrainingLogger:
    """CSVè®­ç»ƒæ—¥å¿—è®°å½•å™¨ï¼Œå…¼å®¹result_excelæ ¼å¼"""

    def __init__(self, save_path: str):
        self.save_path = save_path
        self.csv_file = None
        self.csv_writer = None
        self.start_time = time.time()

    def __enter__(self):
        self.csv_file = open(self.save_path, 'w', newline='')
        self.csv_writer = csv.writer(self.csv_file)
        # å†™å…¥æ ‡å‡†æ ¼å¼çš„å¤´éƒ¨ï¼ˆä¸å…¶ä»–ç®—æ³•ä¸€è‡´ï¼‰
        self.csv_writer.writerow(['Wall time', 'Step', 'Value'])
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.csv_file:
            self.csv_file.close()

    def log(self, timestep: int, reward: float):
        """è®°å½•è®­ç»ƒæ•°æ®ç‚¹"""
        wall_time = time.time()
        self.csv_writer.writerow([wall_time, timestep, reward])
        self.csv_file.flush()  # ç«‹å³å†™å…¥


def run_optimized_impala_with_csv():
    """è¿è¡Œä¼˜åŒ–çš„IMPALAå¹¶ç”ŸæˆCSVæ—¥å¿—"""
    parser = argparse.ArgumentParser(description='Run Optimized IMPALA with CSV logging')
    parser.add_argument('--timesteps', type=int, default=500000,
                        help='Total training timesteps (default: 500000)')
    parser.add_argument('--eval-episodes', type=int, default=10,
                        help='Number of evaluation episodes (default: 10)')
    parser.add_argument('--log-freq', type=int, default=50000,
                        help='Logging frequency in timesteps (default: 50000)')
    parser.add_argument('--csv-file', type=str, default=None,
                        help='CSV output file path (auto-generated if not specified)')

    args = parser.parse_args()

    # ç”ŸæˆCSVæ–‡ä»¶åï¼ˆä¸å…¶ä»–ç®—æ³•æ ¼å¼ä¸€è‡´ï¼‰
    if args.csv_file is None:
        timestamp = int(time.time())
        csv_filename = f"../../Results/excel/IMPALA_Optimized_{timestamp}.csv"
    else:
        csv_filename = args.csv_file

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(csv_filename), exist_ok=True)

    print("ğŸš€ Running Optimized IMPALA with CSV Logging")
    print("=" * 80)
    print(f"ğŸ“Š Configuration:")
    print(f"   Total timesteps: {args.timesteps:,}")
    print(f"   Evaluation episodes: {args.eval_episodes}")
    print(f"   Log frequency: {args.log_freq:,}")
    print(f"   CSV output: {csv_filename}")

    # ä¼˜åŒ–çš„IMPALAé…ç½®
    config = {
        # ä¿å®ˆçš„è¶…å‚æ•°è®¾ç½®ï¼ˆé¿å…è®­ç»ƒå´©æºƒï¼‰
        'learning_rate': 5e-5,
        'rho_bar': 0.8,
        'c_bar': 0.8,
        'buffer_size': 50000,
        'sequence_length': 32,
        'batch_size': 32,
        'hidden_dim': 512,
        'num_layers': 3,
        'entropy_coeff': 0.02,
        'gradient_clip': 10.0,
        'learning_starts': 2000,
        'train_freq': 2,
        'verbose': 1  # å¯ç”¨è¿›åº¦è¾“å‡º
    }

    print(f"\nğŸ¯ IMPALA Optimizations:")
    print(f"   âœ… Mixed action space support")
    print(f"   âœ… Queue-specific network architecture")
    print(f"   âœ… Conservative V-trace: rho_bar={config['rho_bar']}, c_bar={config['c_bar']}")
    print(f"   âœ… Lower learning rate: {config['learning_rate']}")
    print(f"   âœ… Enhanced stability mechanisms")

    # åˆ›å»ºåŸºçº¿
    baseline = OptimizedIMPALABaseline(config=config)

    # è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼ŒåŒ…å«CSVæ—¥å¿—è®°å½•
    print(f"\nğŸƒ Starting training...")

    with CSVTrainingLogger(csv_filename) as logger:

        # è®¾ç½®ç¯å¢ƒå’Œæ™ºèƒ½ä½“
        baseline.setup_env()
        baseline.create_agent()

        # è®­ç»ƒå˜é‡
        episode = 0
        timestep = 0
        episode_reward = 0.0
        episode_length = 0
        recent_rewards = []

        # é‡ç½®ç¯å¢ƒ
        state, _ = baseline.env.reset()
        start_time = time.time()

        while timestep < args.timesteps:
            # é€‰æ‹©åŠ¨ä½œ
            action = baseline.agent.act(state, training=True)

            # æ‰§è¡ŒåŠ¨ä½œ
            try:
                step_result = baseline.env.step(action)
                if len(step_result) == 5:
                    next_state, reward, terminated, truncated, info = step_result
                    done = terminated or truncated
                else:
                    next_state, reward, done, info = step_result
            except Exception as e:
                print(f"âŒ Environment step error: {e}")
                break

            # å­˜å‚¨ç»éªŒ
            baseline.agent.store_transition(state, action, reward, next_state, done)

            # æ›´æ–°ç»Ÿè®¡
            episode_reward += reward
            episode_length += 1
            timestep += 1

            # è®­ç»ƒæ™ºèƒ½ä½“
            if timestep >= config['learning_starts']:
                train_info = baseline.agent.train()

            # Episodeç»“æŸå¤„ç†
            if done:
                # è®°å½•episodeä¿¡æ¯
                baseline.training_history['episode_rewards'].append(episode_reward)
                baseline.training_history['episode_lengths'].append(episode_length)
                recent_rewards.append(episode_reward)

                # ä¿æŒæœ€è¿‘100ä¸ªå¥–åŠ±
                if len(recent_rewards) > 100:
                    recent_rewards.pop(0)

                # æ‰“å°è¿›åº¦
                if episode % 20 == 0:
                    elapsed_time = time.time() - start_time
                    avg_recent = np.mean(recent_rewards) if recent_rewards else 0

                    print(f"Episode {episode:5d} | "
                          f"Timestep {timestep:8d} | "
                          f"Reward: {episode_reward:8.2f} | "
                          f"Avg(recent): {avg_recent:8.2f} | "
                          f"Length: {episode_length:4d} | "
                          f"Time: {elapsed_time:.1f}s")

                # é‡ç½®episode
                episode += 1
                episode_reward = 0.0
                episode_length = 0
                state, _ = baseline.env.reset()
            else:
                state = next_state

            # CSVæ—¥å¿—è®°å½•ï¼ˆæŒ‰é¢‘ç‡ï¼‰
            if timestep % args.log_freq == 0 and timestep > 0:
                # è¿è¡Œå¿«é€Ÿè¯„ä¼°è·å–å½“å‰æ€§èƒ½
                eval_reward = 0.0
                if recent_rewards:
                    eval_reward = np.mean(recent_rewards)
                else:
                    # å¦‚æœæ²¡æœ‰recent_rewardsï¼Œåšä¸€ä¸ªå¿«é€Ÿè¯„ä¼°
                    eval_state, _ = baseline.env.reset()
                    eval_episode_reward = 0.0
                    eval_done = False
                    eval_steps = 0

                    while not eval_done and eval_steps < 200:
                        eval_action = baseline.agent.act(eval_state, training=False)
                        eval_step_result = baseline.env.step(eval_action)

                        if len(eval_step_result) == 5:
                            eval_state, eval_r, eval_terminated, eval_truncated, eval_info = eval_step_result
                            eval_done = eval_terminated or eval_truncated
                        else:
                            eval_state, eval_r, eval_done, eval_info = eval_step_result

                        eval_episode_reward += eval_r
                        eval_steps += 1

                    eval_reward = eval_episode_reward

                # è®°å½•åˆ°CSV
                logger.log(timestep, eval_reward)

                print(f"ğŸ“Š Logged timestep {timestep:,}: reward = {eval_reward:.2f}")

    # è®­ç»ƒå®Œæˆ
    total_time = time.time() - start_time

    print(f"\nâœ… Training completed!")
    print(f"   Total episodes: {episode}")
    print(f"   Total time: {total_time:.2f}s ({total_time/60:.1f}min)")
    print(f"   CSV file saved: {csv_filename}")

    # æœ€ç»ˆè¯„ä¼°
    print(f"\nğŸ“Š Final evaluation...")
    eval_results = baseline.evaluate(n_episodes=args.eval_episodes, deterministic=True, verbose=False)

    print(f"ğŸ“ˆ Final Performance:")
    print(f"   Mean reward: {eval_results['mean_reward']:.2f} Â± {eval_results['std_reward']:.2f}")
    print(f"   Mean length: {eval_results['mean_length']:.1f}")

    # ä¸ä¹‹å‰çš„IMPALAç»“æœæ¯”è¾ƒ
    original_impala_score = 1705.13  # ä»result_excel/prepare_fix.md
    improvement = eval_results['mean_reward'] - original_impala_score
    improvement_pct = (improvement / original_impala_score) * 100

    print(f"\nğŸ“Š Comparison with Original IMPALA:")
    print(f"   Original IMPALA: {original_impala_score:.2f} (with training collapse)")
    print(f"   Optimized IMPALA: {eval_results['mean_reward']:.2f}")
    print(f"   Improvement: {improvement:+.2f} ({improvement_pct:+.1f}%)")

    if improvement > 0:
        print(f"   âœ… Optimization successful!")
        if improvement > 500:
            print(f"   ğŸ‰ Significant improvement achieved!")
    else:
        print(f"   âš ï¸  Performance did not improve as expected")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = "../../Models/impala_optimized_final.pt"
    os.makedirs(os.path.dirname(final_model_path), exist_ok=True)
    baseline.save(final_model_path)
    print(f"ğŸ’¾ Final model saved: {final_model_path}")

    return {
        'final_reward': eval_results['mean_reward'],
        'csv_file': csv_filename,
        'improvement': improvement,
        'training_time': total_time
    }


if __name__ == "__main__":
    try:
        results = run_optimized_impala_with_csv()
        print(f"\nğŸ¯ Summary:")
        print(f"   Final performance: {results['final_reward']:.2f}")
        print(f"   Training time: {results['training_time']:.1f}s")
        print(f"   Improvement: {results['improvement']:+.2f}")
        print(f"   CSV data saved: {results['csv_file']}")

    except KeyboardInterrupt:
        print(f"\nâš ï¸  Training interrupted by user")
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()