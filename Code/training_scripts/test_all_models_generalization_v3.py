"""
Top 3æ¨¡å‹è·¨åŒºåŸŸæ³›åŒ–æ€§æµ‹è¯•è„šæœ¬ V3 - å¥–åŠ±ç»„ä»¶åˆ†è§£ç‰ˆ
Top 3 Models Cross-Region Generalization Test Script V3 - Reward Decomposition

ğŸ¯ æ ¸å¿ƒæ”¹è¿› (V2 â†’ V3):
1. ä¿ç•™V2çš„æ‰€æœ‰å¤šç»´åº¦ç³»ç»ŸæŒ‡æ ‡
2. **æ–°å¢ï¼šæå–å¥–åŠ±ç»„ä»¶åˆ†è§£ (reward_components)**
3. åˆ†æå•ç›®æ ‡ä¼˜åŒ–(RP1)åœ¨å¤šç›®æ ‡æƒè¡¡ä¸Šçš„é™åˆ¶
4. ä¸ºRP1â†’RP2çš„transitionæä¾›ç§‘å­¦ä¾æ®

è¯„ä¼°æŒ‡æ ‡ï¼š
ã€V2æŒ‡æ ‡ã€‘
- ç´¯ç§¯å¥–åŠ± (Cumulative Reward)
- é˜Ÿåˆ—åˆ©ç”¨ç‡ (Queue Utilization)
- è´Ÿè½½ç‡ (Load Rate)
- ç³»ç»Ÿååé‡ (Throughput)
- ç¨³å®šæ€§å¾—åˆ† (Stability Score)

ã€V3æ–°å¢ - å¥–åŠ±ç»„ä»¶ã€‘
- R_throughput: ååé‡å¥–åŠ± (10.0 Ã— æœåŠ¡è®¢å•æ•°)
- R_balance: è´Ÿè½½å‡è¡¡å¥–åŠ± (åŸºå°¼ç³»æ•°, 0-5.0)
- R_efficiency: èƒ½æ•ˆå¥–åŠ± (æœåŠ¡/èƒ½è€—æ¯”, 0-3.0)
- transfer_benefit: è½¬ç§»æ•ˆç›Š (0-2.0)
- stability_bonus: ç¨³å®šæ€§å¥–åŠ± (0-2.0)
- P_congestion: æ‹¥å µæƒ©ç½š (<0)
- P_instability: ä¸ç¨³å®šæƒ©ç½š (<0)

ğŸ“Š åˆ†æç›®çš„ï¼š
æ­ç¤ºRP1çš„å•ç›®æ ‡ä¼˜åŒ–è™½ç„¶è·å¾—é«˜ç´¯ç§¯å¥–åŠ±ï¼Œä½†åœ¨ï¼š
  - å±‚é—´å…¬å¹³æ€§ (R_balance)
  - èƒ½æºæ•ˆç‡ (R_efficiency)
  - è´Ÿè½½å‡è¡¡
å­˜åœ¨trade-offs â†’ motivates RP2çš„MORLæ–¹æ³•
"""

import sys
import os
# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import json
from pathlib import Path
from typing import Dict, List
import time

# å¯¼å…¥åŸºçº¿ç®—æ³•
from algorithms.baselines.sb3_a2c_baseline import SB3A2CBaseline
from algorithms.baselines.sb3_ppo_baseline import SB3PPOBaseline
from algorithms.advanced.td7.td7_baseline import TD7Baseline

# å¯¼å…¥ç¯å¢ƒå’Œé…ç½®
from env.configurable_env_wrapper import ConfigurableEnvWrapper
from algorithms.baselines.space_utils import SB3DictWrapper

# å¯¼å…¥å¼‚è´¨æ€§é…ç½®ç”Ÿæˆå™¨
from heterogeneous_configs import HeterogeneousRegionConfigs


def test_model_in_region(model, model_type: str, config, region_name: str,
                         n_episodes: int = 10, verbose: bool = True):
    """
    åœ¨æŒ‡å®šåŒºåŸŸæµ‹è¯•æ¨¡å‹ - V3ç‰ˆæœ¬ï¼ˆæå–å¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰

    Args:
        model: å·²åŠ è½½æ¨¡å‹çš„baselineå®ä¾‹
        model_type: æ¨¡å‹ç±»å‹ ('A2C', 'PPO', 'TD7')
        config: VerticalQueueConfigé…ç½®
        region_name: åŒºåŸŸåç§°
        n_episodes: æµ‹è¯•episodeæ•°é‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        dict: æµ‹è¯•ç»“æœï¼ˆåŒ…å«å¤šç»´åº¦æŒ‡æ ‡ + å¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰
    """
    if verbose:
        print(f"\n{'='*80}")
        print(f"æµ‹è¯•: {model_type} @ {region_name}")
        print(f"{'='*80}")

    # åˆ›å»ºè¯¥åŒºåŸŸçš„ç¯å¢ƒ
    base_env = ConfigurableEnvWrapper(config)
    eval_env = SB3DictWrapper(base_env)

    # è®°å½•ç»“æœ
    episode_rewards = []
    episode_lengths = []

    # V2æŒ‡æ ‡ï¼šç³»ç»Ÿæ€§èƒ½
    episode_avg_utilizations = []
    episode_avg_load_rates = []
    episode_throughputs = []
    episode_stability_scores = []
    episode_max_utilizations = []

    # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶
    episode_avg_r_throughput = []
    episode_avg_r_balance = []
    episode_avg_r_efficiency = []
    episode_avg_transfer = []
    episode_avg_stability_bonus = []
    episode_avg_p_congestion = []
    episode_avg_p_instability = []

    episode_details = []

    # è¿è¡Œn_episodesä¸ªepisode
    for episode in range(n_episodes):
        obs, info = eval_env.reset()
        episode_reward = 0
        episode_length = 0
        done = False

        # V2æŒ‡æ ‡æ”¶é›†
        step_utilizations = []
        step_load_rates = []
        step_stability_scores = []

        # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶æ”¶é›†
        step_r_throughput = []
        step_r_balance = []
        step_r_efficiency = []
        step_transfer = []
        step_stability_bonus = []
        step_p_congestion = []
        step_p_instability = []

        # è¿è¡Œä¸€ä¸ªå®Œæ•´çš„episode
        while not done:
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©é¢„æµ‹æ–¹æ³•
            if model_type == 'TD7':
                action = model.agent.act(obs, training=False)
            else:  # A2C or PPO
                action, _ = model.model.predict(obs, deterministic=True)

            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, terminated, truncated, info = eval_env.step(action)
            done = terminated or truncated

            episode_reward += reward
            episode_length += 1

            # æå–V2ç³»ç»ŸæŒ‡æ ‡
            if 'utilization_rates' in info:
                step_utilizations.append(np.mean(info['utilization_rates']))
            if 'load_rates' in info:
                step_load_rates.append(np.mean(info['load_rates']))
            if 'stability_score' in info:
                step_stability_scores.append(info['stability_score'])

            # V3æ–°å¢ï¼šæå–å¥–åŠ±ç»„ä»¶
            if 'reward_components' in info:
                rc = info['reward_components']
                step_r_throughput.append(rc.get('throughput', 0.0))
                step_r_balance.append(rc.get('balance', 0.0))
                step_r_efficiency.append(rc.get('efficiency', 0.0))
                step_transfer.append(rc.get('transfer', 0.0))
                step_stability_bonus.append(rc.get('stability', 0.0))
                step_p_congestion.append(rc.get('congestion', 0.0))
                step_p_instability.append(rc.get('instability', 0.0))

            # é˜²æ­¢æ— é™å¾ªç¯
            if episode_length >= 1000:
                if verbose:
                    print(f"  âš ï¸  Episode {episode+1} è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ (1000)")
                break

        # è®¡ç®—episodeçº§åˆ«çš„ç»Ÿè®¡
        # V2æŒ‡æ ‡
        avg_utilization = np.mean(step_utilizations) if step_utilizations else 0.0
        avg_load_rate = np.mean(step_load_rates) if step_load_rates else 0.0
        avg_stability = np.mean(step_stability_scores) if step_stability_scores else 0.0
        max_utilization = np.max(step_utilizations) if step_utilizations else 0.0
        throughput = info.get('throughput', 0.0) if info else 0.0

        # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶å¹³å‡å€¼
        avg_r_throughput = np.mean(step_r_throughput) if step_r_throughput else 0.0
        avg_r_balance = np.mean(step_r_balance) if step_r_balance else 0.0
        avg_r_efficiency = np.mean(step_r_efficiency) if step_r_efficiency else 0.0
        avg_transfer = np.mean(step_transfer) if step_transfer else 0.0
        avg_stability_bonus = np.mean(step_stability_bonus) if step_stability_bonus else 0.0
        avg_p_congestion = np.mean(step_p_congestion) if step_p_congestion else 0.0
        avg_p_instability = np.mean(step_p_instability) if step_p_instability else 0.0

        # è®°å½•ç»“æœ
        episode_rewards.append(episode_reward)
        episode_lengths.append(episode_length)

        # V2æŒ‡æ ‡
        episode_avg_utilizations.append(avg_utilization)
        episode_avg_load_rates.append(avg_load_rate)
        episode_throughputs.append(throughput)
        episode_stability_scores.append(avg_stability)
        episode_max_utilizations.append(max_utilization)

        # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶
        episode_avg_r_throughput.append(avg_r_throughput)
        episode_avg_r_balance.append(avg_r_balance)
        episode_avg_r_efficiency.append(avg_r_efficiency)
        episode_avg_transfer.append(avg_transfer)
        episode_avg_stability_bonus.append(avg_stability_bonus)
        episode_avg_p_congestion.append(avg_p_congestion)
        episode_avg_p_instability.append(avg_p_instability)

        episode_details.append({
            'episode': episode + 1,
            'reward': float(episode_reward),
            'length': int(episode_length),
            # V2æŒ‡æ ‡
            'avg_utilization': float(avg_utilization),
            'avg_load_rate': float(avg_load_rate),
            'throughput': float(throughput),
            'stability_score': float(avg_stability),
            'max_utilization': float(max_utilization),
            # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶
            'reward_components': {
                'throughput': float(avg_r_throughput),
                'balance': float(avg_r_balance),
                'efficiency': float(avg_r_efficiency),
                'transfer': float(avg_transfer),
                'stability': float(avg_stability_bonus),
                'congestion': float(avg_p_congestion),
                'instability': float(avg_p_instability)
            }
        })

        if verbose:
            print(f"  Episode {episode+1}/{n_episodes}:")
            print(f"    Reward={episode_reward:.2f}, Length={episode_length}")
            print(f"    [V2] Util={avg_utilization:.3f}, Load={avg_load_rate:.3f}, Throughput={throughput:.2f}")
            print(f"    [V3] R_throughput={avg_r_throughput:.1f}, R_balance={avg_r_balance:.2f}, R_efficiency={avg_r_efficiency:.2f}")

    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    results = {
        'model_type': model_type,
        'region_name': region_name,
        'n_episodes': n_episodes,

        # åŸæœ‰æŒ‡æ ‡
        'mean_reward': float(np.mean(episode_rewards)),
        'std_reward': float(np.std(episode_rewards)),
        'mean_length': float(np.mean(episode_lengths)),

        # V2æŒ‡æ ‡ï¼šç³»ç»Ÿæ€§èƒ½
        'mean_utilization': float(np.mean(episode_avg_utilizations)),
        'std_utilization': float(np.std(episode_avg_utilizations)),
        'mean_load_rate': float(np.mean(episode_avg_load_rates)),
        'std_load_rate': float(np.std(episode_avg_load_rates)),
        'mean_throughput': float(np.mean(episode_throughputs)),
        'std_throughput': float(np.std(episode_throughputs)),
        'mean_stability': float(np.mean(episode_stability_scores)),
        'std_stability': float(np.std(episode_stability_scores)),
        'mean_max_congestion': float(np.mean(episode_max_utilizations)),
        'std_max_congestion': float(np.std(episode_max_utilizations)),

        # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶ç»Ÿè®¡
        'reward_components': {
            'mean_throughput': float(np.mean(episode_avg_r_throughput)),
            'std_throughput': float(np.std(episode_avg_r_throughput)),
            'mean_balance': float(np.mean(episode_avg_r_balance)),
            'std_balance': float(np.std(episode_avg_r_balance)),
            'mean_efficiency': float(np.mean(episode_avg_r_efficiency)),
            'std_efficiency': float(np.std(episode_avg_r_efficiency)),
            'mean_transfer': float(np.mean(episode_avg_transfer)),
            'std_transfer': float(np.std(episode_avg_transfer)),
            'mean_stability': float(np.mean(episode_avg_stability_bonus)),
            'std_stability': float(np.std(episode_avg_stability_bonus)),
            'mean_congestion': float(np.mean(episode_avg_p_congestion)),
            'std_congestion': float(np.std(episode_avg_p_congestion)),
            'mean_instability': float(np.mean(episode_avg_p_instability)),
            'std_instability': float(np.std(episode_avg_p_instability))
        },

        # è¯¦ç»†æ•°æ®
        'episode_rewards': [float(r) for r in episode_rewards],
        'episode_lengths': [int(l) for l in episode_lengths],
        'episode_details': episode_details,
        'config_summary': base_env.get_config_summary()
    }

    if verbose:
        print(f"\nğŸ“Š {model_type} @ {region_name} æµ‹è¯•ç»“æœ:")
        print(f"   ã€V2æŒ‡æ ‡ã€‘")
        print(f"   ç´¯ç§¯å¥–åŠ±: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
        print(f"   é˜Ÿåˆ—åˆ©ç”¨ç‡: {results['mean_utilization']:.3f} Â± {results['std_utilization']:.3f}")
        print(f"   è´Ÿè½½ç‡: {results['mean_load_rate']:.3f} Â± {results['std_load_rate']:.3f}")
        print(f"   ååé‡: {results['mean_throughput']:.2f} Â± {results['std_throughput']:.2f}")
        print(f"   ç¨³å®šæ€§: {results['mean_stability']:.3f} Â± {results['std_stability']:.3f}")
        print(f"\n   ã€V3å¥–åŠ±ç»„ä»¶ã€‘")
        rc = results['reward_components']
        print(f"   R_throughput: {rc['mean_throughput']:.2f} Â± {rc['std_throughput']:.2f}")
        print(f"   R_balance (å…¬å¹³æ€§): {rc['mean_balance']:.2f} Â± {rc['std_balance']:.2f}")
        print(f"   R_efficiency (èƒ½æ•ˆ): {rc['mean_efficiency']:.2f} Â± {rc['std_efficiency']:.2f}")
        print(f"   P_congestion (æ‹¥å µæƒ©ç½š): {rc['mean_congestion']:.2f} Â± {rc['std_congestion']:.2f}")

    # æ¸…ç†ç¯å¢ƒ
    eval_env.close()

    return results


def main():
    """ä¸»å‡½æ•°ï¼šæµ‹è¯•æ‰€æœ‰3ä¸ªæ¨¡å‹åœ¨æ‰€æœ‰å¼‚è´¨æ€§åŒºåŸŸçš„æ³›åŒ–æ€§èƒ½ - V3ç‰ˆæœ¬ï¼ˆå¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰"""

    print("\n" + "="*80)
    print("Top 3 æ¨¡å‹è·¨åŒºåŸŸæ³›åŒ–æ€§æµ‹è¯• V3 - å¥–åŠ±ç»„ä»¶åˆ†è§£ç‰ˆ")
    print("Cross-Region Generalization Test V3 - Reward Component Decomposition")
    print("="*80 + "\n")

    print("ğŸ¯ V3æ ¸å¿ƒæ”¹è¿›ï¼š")
    print("   - ä¿ç•™V2çš„å¤šç»´åº¦ç³»ç»ŸæŒ‡æ ‡")
    print("   - æ–°å¢ï¼šæå–å¥–åŠ±ç»„ä»¶åˆ†è§£ (7ä¸ªç»„ä»¶)")
    print("   - æ­ç¤ºå•ç›®æ ‡ä¼˜åŒ–çš„å¤šç›®æ ‡trade-offs")
    print("   - ä¸ºRP1â†’RP2 transitionæä¾›ç§‘å­¦ä¾æ®\n")

    # ========== ç¬¬1æ­¥ï¼šåŠ è½½è®­ç»ƒå¥½çš„3ä¸ªæ¨¡å‹ ==========
    print("ç¬¬1æ­¥ï¼šåŠ è½½è®­ç»ƒå¥½çš„3ä¸ªæ¨¡å‹")
    print("-"*80)

    models = {}
    model_paths = {
        'A2C': '../../Models/a2c/a2c_model_500000',
        'PPO': '../../Models/ppo/ppo_model_500000',
        'TD7': '../../Models/td7/td7_model_500000.pt'
    }

    # åŠ è½½A2C
    print("\n1.1 åŠ è½½A2Cæ¨¡å‹...")
    if not os.path.exists(model_paths['A2C'] + '.pth'):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°A2Cæ¨¡å‹æ–‡ä»¶ {model_paths['A2C']}.pth")
        return

    a2c = SB3A2CBaseline()
    a2c.load(model_paths['A2C'])
    models['A2C'] = a2c
    print("âœ… A2Cæ¨¡å‹åŠ è½½æˆåŠŸï¼")

    # åŠ è½½PPO
    print("\n1.2 åŠ è½½PPOæ¨¡å‹...")
    if not os.path.exists(model_paths['PPO'] + '.pth'):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°PPOæ¨¡å‹æ–‡ä»¶ {model_paths['PPO']}.pth")
        return

    ppo = SB3PPOBaseline()
    ppo.load(model_paths['PPO'])
    models['PPO'] = ppo
    print("âœ… PPOæ¨¡å‹åŠ è½½æˆåŠŸï¼")

    # åŠ è½½TD7
    print("\n1.3 åŠ è½½TD7æ¨¡å‹...")
    if not os.path.exists(model_paths['TD7']):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°TD7æ¨¡å‹æ–‡ä»¶ {model_paths['TD7']}")
        return

    print(f"ğŸ“‚ æ¨¡å‹æ–‡ä»¶å¤§å°: {os.path.getsize(model_paths['TD7']) / (1024*1024):.1f} MB")
    td7 = TD7Baseline()
    td7.load(model_paths['TD7'])
    models['TD7'] = td7
    print("âœ… TD7æ¨¡å‹åŠ è½½æˆåŠŸï¼")

    print("\nâœ… æ‰€æœ‰3ä¸ªæ¨¡å‹åŠ è½½å®Œæˆï¼")

    # ========== ç¬¬2æ­¥ï¼šåˆ›å»ºå¼‚è´¨æ€§åŒºåŸŸé…ç½® ==========
    print("\nç¬¬2æ­¥ï¼šåˆ›å»ºå¼‚è´¨æ€§åŒºåŸŸé…ç½®")
    print("-"*80)

    config_generator = HeterogeneousRegionConfigs()
    all_configs = config_generator.get_all_configs()

    print(f"âœ… å·²åˆ›å»º {len(all_configs)} ä¸ªåŒºåŸŸé…ç½®:")
    for region_name in all_configs.keys():
        print(f"   - {region_name}")

    # ========== ç¬¬3æ­¥ï¼šåœ¨æ¯ä¸ªåŒºåŸŸè¿è¡Œæµ‹è¯• ==========
    print("\nç¬¬3æ­¥ï¼šåœ¨æ¯ä¸ªåŒºåŸŸè¿è¡Œæ³›åŒ–æµ‹è¯•ï¼ˆV3 - å¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰")
    print("-"*80)
    print("âš ï¸  è¿™æ˜¯çœŸå®æµ‹è¯•ï¼Œä¸æ˜¯mockæ•°æ®ï¼")
    print(f"   æ€»æµ‹è¯•æ•°: {len(models)} æ¨¡å‹ Ã— {len(all_configs)} åŒºåŸŸ Ã— 10 episodes = {len(models) * len(all_configs) * 10} episodes")

    all_results = {
        'A2C': {},
        'PPO': {},
        'TD7': {}
    }

    n_episodes_per_region = 10
    start_time = time.time()

    # å¯¹æ¯ä¸ªæ¨¡å‹å’Œæ¯ä¸ªåŒºåŸŸè¿è¡Œæµ‹è¯•
    for model_name in ['A2C', 'PPO', 'TD7']:
        print(f"\n{'='*80}")
        print(f"å¼€å§‹æµ‹è¯• {model_name} æ¨¡å‹")
        print(f"{'='*80}")

        model = models[model_name]

        for region_name, config in all_configs.items():
            results = test_model_in_region(
                model=model,
                model_type=model_name,
                config=config,
                region_name=region_name,
                n_episodes=n_episodes_per_region,
                verbose=True
            )
            all_results[model_name][region_name] = results

    total_time = time.time() - start_time

    # ========== ç¬¬4æ­¥ï¼šæ±‡æ€»ç»“æœï¼ˆV3 - åŒ…å«å¥–åŠ±ç»„ä»¶åˆ†æï¼‰ ==========
    print("\n" + "="*80)
    print("æµ‹è¯•å®Œæˆï¼æ±‡æ€»ç»“æœï¼ˆV3 - å¤šç»´åº¦æŒ‡æ ‡ + å¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰")
    print("="*80 + "\n")

    # è¡¨1: ç´¯ç§¯å¥–åŠ±å¯¹æ¯”
    print("ã€è¡¨1ã€‘ç´¯ç§¯å¥–åŠ±å¯¹æ¯” (Cumulative Reward)")
    print("-"*90)
    print(f"{'åŒºåŸŸ':<30} {'A2C':<20} {'PPO':<20} {'TD7':<20}")
    print("-"*90)

    baseline_rewards = {}

    for region_name in all_configs.keys():
        a2c_reward = all_results['A2C'][region_name]['mean_reward']
        ppo_reward = all_results['PPO'][region_name]['mean_reward']
        td7_reward = all_results['TD7'][region_name]['mean_reward']

        if 'Standard' in region_name:
            baseline_rewards['A2C'] = a2c_reward
            baseline_rewards['PPO'] = ppo_reward
            baseline_rewards['TD7'] = td7_reward

        print(f"{region_name:<30} {a2c_reward:<20.2f} {ppo_reward:<20.2f} {td7_reward:<20.2f}")

    # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶å¯¹æ¯”è¡¨æ ¼
    print("\nã€è¡¨6ã€‘R_balance (è´Ÿè½½å‡è¡¡/å…¬å¹³æ€§) å¯¹æ¯”")
    print("-"*90)
    print(f"{'åŒºåŸŸ':<30} {'A2C':<20} {'PPO':<20} {'TD7':<20}")
    print("-"*90)

    for region_name in all_configs.keys():
        a2c_bal = all_results['A2C'][region_name]['reward_components']['mean_balance']
        ppo_bal = all_results['PPO'][region_name]['reward_components']['mean_balance']
        td7_bal = all_results['TD7'][region_name]['reward_components']['mean_balance']

        print(f"{region_name:<30} {a2c_bal:<20.3f} {ppo_bal:<20.3f} {td7_bal:<20.3f}")

    print("\nã€è¡¨7ã€‘R_efficiency (èƒ½æºæ•ˆç‡) å¯¹æ¯”")
    print("-"*90)
    print(f"{'åŒºåŸŸ':<30} {'A2C':<20} {'PPO':<20} {'TD7':<20}")
    print("-"*90)

    for region_name in all_configs.keys():
        a2c_eff = all_results['A2C'][region_name]['reward_components']['mean_efficiency']
        ppo_eff = all_results['PPO'][region_name]['reward_components']['mean_efficiency']
        td7_eff = all_results['TD7'][region_name]['reward_components']['mean_efficiency']

        print(f"{region_name:<30} {a2c_eff:<20.3f} {ppo_eff:<20.3f} {td7_eff:<20.3f}")

    print("\nã€è¡¨8ã€‘R_throughput (ååé‡å¥–åŠ±ç»„ä»¶) å¯¹æ¯”")
    print("-"*90)
    print(f"{'åŒºåŸŸ':<30} {'A2C':<20} {'PPO':<20} {'TD7':<20}")
    print("-"*90)

    for region_name in all_configs.keys():
        a2c_thr = all_results['A2C'][region_name]['reward_components']['mean_throughput']
        ppo_thr = all_results['PPO'][region_name]['reward_components']['mean_throughput']
        td7_thr = all_results['TD7'][region_name]['reward_components']['mean_throughput']

        print(f"{region_name:<30} {a2c_thr:<20.2f} {ppo_thr:<20.2f} {td7_thr:<20.2f}")

    print("\nã€è¡¨9ã€‘P_congestion (æ‹¥å µæƒ©ç½š) å¯¹æ¯”")
    print("-"*90)
    print(f"{'åŒºåŸŸ':<30} {'A2C':<20} {'PPO':<20} {'TD7':<20}")
    print("-"*90)

    for region_name in all_configs.keys():
        a2c_cong = all_results['A2C'][region_name]['reward_components']['mean_congestion']
        ppo_cong = all_results['PPO'][region_name]['reward_components']['mean_congestion']
        td7_cong = all_results['TD7'][region_name]['reward_components']['mean_congestion']

        print(f"{region_name:<30} {a2c_cong:<20.2f} {ppo_cong:<20.2f} {td7_cong:<20.2f}")

    print("\n" + "-"*80)
    print(f"æ€»æµ‹è¯•æ—¶é—´: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    print(f"æ€»episodeæ•°: {len(models) * len(all_configs) * n_episodes_per_region}")

    # ========== ç¬¬5æ­¥ï¼šä¿å­˜ç»“æœ ==========
    print("\nç¬¬5æ­¥ï¼šä¿å­˜æµ‹è¯•ç»“æœ (V3ç‰ˆæœ¬)")
    print("-"*80)

    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path("../../Results/generalization")
    save_dir.mkdir(exist_ok=True)

    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = save_dir / "all_models_generalization_results_v3.json"

    full_results = {
        'test_info': {
            'version': 'v3_reward_decomposition',
            'test_date': time.strftime("%Y-%m-%d %H:%M:%S"),
            'n_episodes_per_region': n_episodes_per_region,
            'total_time_seconds': total_time,
            'models_tested': ['A2C', 'PPO', 'TD7'],
            'regions_tested': list(all_configs.keys()),
            'metrics_evaluated': {
                'v2_system_metrics': [
                    'cumulative_reward', 'queue_utilization', 'load_rate',
                    'throughput', 'stability_score', 'max_congestion'
                ],
                'v3_reward_components': [
                    'R_throughput', 'R_balance', 'R_efficiency',
                    'transfer_benefit', 'stability_bonus',
                    'P_congestion', 'P_instability'
                ]
            },
            'purpose': 'Reveal multi-objective trade-offs in single-objective RL (RP1) to motivate MORL approach (RP2)'
        },
        'model_paths': model_paths,
        'baseline_performance': {
            'A2C': f"{baseline_rewards['A2C']:.2f}",
            'PPO': f"{baseline_rewards['PPO']:.2f}",
            'TD7': f"{baseline_rewards['TD7']:.2f}"
        },
        'results': all_results
    }

    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(full_results, f, indent=2, ensure_ascii=False)

    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

    # ä¿å­˜æ±‡æ€»è¡¨æ ¼ï¼ˆCSVæ ¼å¼ - V3å¢å¼ºç‰ˆï¼ŒåŒ…å«å¥–åŠ±ç»„ä»¶ï¼‰
    summary_file = save_dir / "all_models_generalization_summary_v3.csv"
    import csv

    with open(summary_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow([
            'Region', 'Model',
            'Mean Reward', 'Std Reward',
            'Mean Utilization', 'Std Utilization',
            'Mean Load Rate', 'Std Load Rate',
            'Mean Throughput', 'Std Throughput',
            'Mean Stability', 'Std Stability',
            # V3æ–°å¢ï¼šå¥–åŠ±ç»„ä»¶
            'R_throughput', 'R_balance', 'R_efficiency',
            'transfer_benefit', 'stability_bonus',
            'P_congestion', 'P_instability'
        ])

        for region_name in all_configs.keys():
            for model_name in ['A2C', 'PPO', 'TD7']:
                res = all_results[model_name][region_name]
                rc = res['reward_components']
                writer.writerow([
                    region_name, model_name,
                    f"{res['mean_reward']:.2f}", f"{res['std_reward']:.2f}",
                    f"{res['mean_utilization']:.4f}", f"{res['std_utilization']:.4f}",
                    f"{res['mean_load_rate']:.4f}", f"{res['std_load_rate']:.4f}",
                    f"{res['mean_throughput']:.2f}", f"{res['std_throughput']:.2f}",
                    f"{res['mean_stability']:.4f}", f"{res['std_stability']:.4f}",
                    # V3æ–°å¢
                    f"{rc['mean_throughput']:.2f}", f"{rc['mean_balance']:.3f}", f"{rc['mean_efficiency']:.3f}",
                    f"{rc['mean_transfer']:.3f}", f"{rc['mean_stability']:.3f}",
                    f"{rc['mean_congestion']:.3f}", f"{rc['mean_instability']:.3f}"
                ])

    print(f"âœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ°: {summary_file}")

    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰æ¨¡å‹æ³›åŒ–æ€§æµ‹è¯•å…¨éƒ¨å®Œæˆï¼ˆV3 - å¥–åŠ±ç»„ä»¶åˆ†è§£ç‰ˆï¼‰ï¼")
    print("="*80 + "\n")

    print("ğŸ“Œ V3å…³é”®å‘ç°ï¼ˆå¥–åŠ±ç»„ä»¶åˆ†è§£ï¼‰:")
    print(f"\n   Baselineæ€§èƒ½ (Region A - Standard):")
    print(f"     - A2C: {baseline_rewards['A2C']:.2f}")
    print(f"     - PPO: {baseline_rewards['PPO']:.2f}")
    print(f"     - TD7: {baseline_rewards['TD7']:.2f}")

    print(f"\n   ğŸ¯ RP1â†’RP2 Transition Logic:")
    print(f"   è™½ç„¶RP1çš„å•ç›®æ ‡ä¼˜åŒ–è·å¾—äº†é«˜ç´¯ç§¯å¥–åŠ±ï¼Œ")
    print(f"   ä½†å¥–åŠ±ç»„ä»¶åˆ†è§£æ˜¾ç¤ºåœ¨å¤šä¸ªç›®æ ‡ä¸Šå­˜åœ¨trade-offsï¼š")
    print(f"     - R_balance (å…¬å¹³æ€§): å±‚é—´è´Ÿè½½åˆ†å¸ƒä¸å‡")
    print(f"     - R_efficiency (èƒ½æ•ˆ): èƒ½æºåˆ©ç”¨ç‡è¾ƒä½")
    print(f"     - P_congestion (æ‹¥å µ): é«˜è´Ÿè½½ä¸‹æ‹¥å µå¢åŠ ")
    print(f"   è¿™äº›trade-offsæ­ç¤ºäº†å•ç›®æ ‡ä¼˜åŒ–çš„å±€é™æ€§ï¼Œ")
    print(f"   motivates RP2é‡‡ç”¨MORLæ–¹æ³•è¿›è¡Œå¸•ç´¯æ‰˜ä¼˜åŒ–ã€‚")

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
    print("   1. æŸ¥çœ‹è¯¦ç»†ç»“æœ: cat generalization_results/all_models_generalization_results_v3.json")
    print("   2. æŸ¥çœ‹æ±‡æ€»è¡¨æ ¼: cat generalization_results/all_models_generalization_summary_v3.csv")
    print("   3. åˆ†æå¥–åŠ±ç»„ä»¶trade-offsï¼Œè®¾è®¡RP1â†’RP2 transitioné€»è¾‘")
    print("   4. æ’°å†™è®ºæ–‡Section 3.4: è·¨åœºæ™¯æ³›åŒ–æ€§åˆ†æ + RP2 motivation")


if __name__ == "__main__":
    main()
