"""
Ablation Study Experiment Runner

Run complete ablation study including:
1. Full system (control group)
2. No high priority experiment
3. Single objective optimization experiment
4. Traditional pyramid experiment
5. No transfer mechanism experiment

Usage:
    python run_ablation_experiments.py --timesteps 100000 --all
    python run_ablation_experiments.py --experiment no_high_priority --timesteps 50000
    python run_ablation_experiments.py --quick-test
"""

import argparse
import os
import sys
import json
import time
import numpy as np
from datetime import datetime
from typing import Dict, List, Any

# Add project path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from algorithms.baselines.sb3_ablation_baseline import SB3AblationBaseline, AblationExperimentManager
from ablation_configs import AblationConfigs


class AblationExperimentRunner:
    """Ablation experiment runner"""

    def __init__(self, output_dir="./ablation_results/"):
        self.output_dir = output_dir
        self.results = {}
        self.start_time = None

        # Create output directories
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(f"../../Models/", exist_ok=True)
        os.makedirs(f"{output_dir}/logs/", exist_ok=True)
        
    def run_single_experiment(self, ablation_type: str, timesteps: int = 100000,
                            eval_episodes: int = 30) -> Dict[str, Any]:
        """
        Run single ablation experiment

        Args:
            ablation_type: Ablation experiment type
            timesteps: Training timesteps
            eval_episodes: Evaluation episodes

        Returns:
            Experiment results dictionary
        """
        print(f"\nğŸ¯ Running ablation experiment: {ablation_type}")
        print(f"   Training timesteps: {timesteps:,}")
        print(f"   Evaluation episodes: {eval_episodes}")
        print("=" * 50)

        experiment_start = time.time()

        try:
            # Create ablation baseline
            baseline = SB3AblationBaseline(ablation_type)

            # Train model
            print(f"ğŸš€ Starting training...")
            baseline.train(total_timesteps=timesteps)

            # Evaluate performance
            print(f"ğŸ“Š Starting evaluation...")
            results = baseline.evaluate(n_episodes=eval_episodes)

            # Add experiment metadata
            experiment_time = time.time() - experiment_start
            results.update({
                'timesteps': timesteps,
                'eval_episodes': eval_episodes,
                'experiment_time': experiment_time,
                'timestamp': datetime.now().isoformat(),
                'success': True
            })

            print(f"âœ… {ablation_type} experiment completed!")
            print(f"   Training time: {experiment_time:.1f}s")
            print(f"   Mean reward: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
            
            return results
            
        except Exception as e:
            error_result = {
                'ablation_type': ablation_type,
                'error': str(e),
                'timesteps': timesteps,
                'success': False,
                'timestamp': datetime.now().isoformat()
            }
            
            print(f"âŒ {ablation_type} experiment failed: {str(e)}")
            return error_result

    def run_all_experiments(self, timesteps: int = 100000, eval_episodes: int = 30) -> Dict[str, Any]:
        """
        Run all ablation experiments

        Args:
            timesteps: Training timesteps per experiment
            eval_episodes: Evaluation episodes per experiment

        Returns:
            All experiment results
        """
        self.start_time = time.time()

        # Get all ablation experiment types
        ablation_types = [
            'full_system',      # Full system (control group)
            'no_high_priority', # No high priority
            'single_objective', # Single objective optimization
            'traditional_pyramid', # Traditional pyramid
            'no_transfer'       # No transfer mechanism
        ]

        print(f"ğŸ§ª Starting complete ablation study")
        print(f"   Number of experiments: {len(ablation_types)}")
        print(f"   Training timesteps per experiment: {timesteps:,}")
        print(f"   Evaluation episodes per experiment: {eval_episodes}")
        print(f"   Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # Run each experiment
        for i, ablation_type in enumerate(ablation_types, 1):
            print(f"\nğŸ“ˆ Progress: {i}/{len(ablation_types)} - {ablation_type}")

            # Run single experiment
            result = self.run_single_experiment(ablation_type, timesteps, eval_episodes)
            self.results[ablation_type] = result

            # Save intermediate results
            self._save_intermediate_results()

            # Print current comparison
            if i > 1:  # Only compare when at least 2 results exist
                self._print_current_comparison()

        # Complete all experiments
        total_time = time.time() - self.start_time
        print(f"\nğŸ‰ Ablation study completed!")
        print(f"   Total time: {total_time:.1f}s ({total_time/60:.1f}min)")

        # Generate final report
        self._generate_final_report()
        
        return self.results

    def _save_intermediate_results(self):
        """Save intermediate results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = f"{self.output_dir}/intermediate_results_{timestamp}.json"

        # Convert numpy types to Python native types
        results_serializable = self._convert_numpy_types(self.results)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_serializable, f, indent=2, ensure_ascii=False)

    def _convert_numpy_types(self, obj):
        """Convert numpy types to JSON-serializable Python types"""
        if isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        else:
            return obj
    
    def _print_current_comparison(self):
        """Print current comparison results"""
        if len(self.results) < 2:
            return

        print(f"\nğŸ“Š Current comparison results:")
        print("-" * 70)
        print(f"{'Experiment Type':<20} {'Mean Reward':<12} {'Std Dev':<8} {'Performance Change':<10} {'Status'}")
        print("-" * 70)

        full_system_reward = None
        if 'full_system' in self.results and self.results['full_system'].get('success'):
            full_system_reward = self.results['full_system']['mean_reward']

        for ablation_type, result in self.results.items():
            if not result.get('success', False):
                print(f"{ablation_type:<20} {'ERROR':<12} {'-':<8} {'-':<10} {'âŒ'}")
                continue

            mean_reward = result['mean_reward']
            std_reward = result['std_reward']

            if ablation_type == 'full_system':
                change = "Baseline"
                status = "âœ…"
            elif full_system_reward:
                change_percent = (mean_reward - full_system_reward) / full_system_reward * 100
                change = f"{change_percent:+.1f}%"
                status = "âœ…" if change_percent > -5 else "ğŸ“‰"
            else:
                change = "Pending"
                status = "â³"

            print(f"{ablation_type:<20} {mean_reward:<12.2f} {std_reward:<8.2f} {change:<10} {status}")

        print("-" * 70)

    def _generate_final_report(self):
        """Generate final experiment report"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # JSON results
        json_path = f"{self.output_dir}/final_ablation_results_{timestamp}.json"
        results_serializable = self._convert_numpy_types(self.results)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_serializable, f, indent=2, ensure_ascii=False)

        # Markdown report
        md_path = f"{self.output_dir}/ablation_report_{timestamp}.md"
        self._create_markdown_report(md_path)

        print(f"ğŸ“„ Reports generated:")
        print(f"   JSON results: {json_path}")
        print(f"   Markdown report: {md_path}")

    def _create_markdown_report(self, filepath: str):
        """Create Markdown format experiment report"""

        # Get experiment plan information
        experiment_plan = AblationConfigs.get_ablation_experiment_plan()

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("# Ablation Study Research Report\n\n")

            f.write(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
            f.write(f"**Number of experiments**: {len(self.results)}  \n")
            if self.start_time:
                total_time = time.time() - self.start_time
                f.write(f"**Total time**: {total_time:.1f}s ({total_time/60:.1f}min)  \n")
            f.write("\\n")

            # Experiment results table
            f.write("## ğŸ“Š Experiment Results Comparison\n\n")
            f.write("| Experiment Type | Mean Reward | Std Dev | Performance Change | Removed Component | Status |\\n")
            f.write("|----------------|-------------|---------|-------------------|-------------------|--------|\\n")
            
            full_system_reward = None
            if 'full_system' in self.results and self.results['full_system'].get('success'):
                full_system_reward = self.results['full_system']['mean_reward']
            
            for ablation_type, result in self.results.items():
                plan_info = experiment_plan.get(ablation_type, {})
                removed_component = plan_info.get('removed_component', 'None')
                
                if not result.get('success', False):
                    f.write(f"| {ablation_type} | ERROR | - | - | {removed_component} | âŒ |\\n")
                    continue
                
                mean_reward = result['mean_reward']
                std_reward = result['std_reward']
                
                if ablation_type == 'full_system':
                    change = "åŸºå‡† (100%)"
                    status = "âœ…"
                elif full_system_reward:
                    change_percent = (mean_reward - full_system_reward) / full_system_reward * 100
                    change = f"{change_percent:+.1f}%"
                    status = "âœ…" if change_percent > -5 else "ğŸ“‰"
                else:
                    change = "å¾…å®š"
                    status = "â³"
                
                f.write(f"| {ablation_type} | {mean_reward:.2f} | {std_reward:.2f} | {change} | {removed_component} | {status} |\\n")
            
            # è¯¦ç»†å®éªŒä¿¡æ¯
            f.write("\\n## ğŸ§ª è¯¦ç»†å®éªŒä¿¡æ¯\\n\\n")
            
            for ablation_type, result in self.results.items():
                plan_info = experiment_plan.get(ablation_type, {})
                f.write(f"### {plan_info.get('name', ablation_type)}\\n\\n")
                f.write(f"**æè¿°**: {plan_info.get('description', 'N/A')}  \\n")
                
                if 'removed_component' in plan_info:
                    f.write(f"**ç§»é™¤ç»„ä»¶**: {plan_info['removed_component']}  \\n")
                
                if 'hypothesis' in plan_info:
                    f.write(f"**å‡è®¾**: {plan_info['hypothesis']}  \\n")
                
                if result.get('success'):
                    f.write(f"**å®éªŒç»“æœ**:  \\n")
                    f.write(f"- å¹³å‡å¥–åŠ±: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}  \\n")
                    f.write(f"- è®­ç»ƒæ­¥æ•°: {result['timesteps']:,}  \\n")
                    f.write(f"- è¯„ä¼°å›åˆ: {result['eval_episodes']}  \\n")
                    f.write(f"- å®éªŒç”¨æ—¶: {result['experiment_time']:.1f}s  \\n")
                else:
                    f.write(f"**å®éªŒå¤±è´¥**: {result.get('error', 'Unknown error')}  \\n")
                
                f.write("\\n")
            
            # ç»“è®ºå’Œåˆ†æ
            f.write("## ğŸ¯ ç»“è®ºä¸åˆ†æ\\n\\n")
            
            if full_system_reward:
                f.write("### ç»„ä»¶è´¡çŒ®åº¦æ’åº\\n\\n")
                
                contributions = []
                for ablation_type, result in self.results.items():
                    if ablation_type == 'full_system' or not result.get('success'):
                        continue
                    
                    contribution = (full_system_reward - result['mean_reward']) / full_system_reward * 100
                    removed_component = experiment_plan.get(ablation_type, {}).get('removed_component', ablation_type)
                    contributions.append((removed_component, contribution, ablation_type))
                
                contributions.sort(key=lambda x: x[1], reverse=True)
                
                for i, (component, contribution, ablation_type) in enumerate(contributions, 1):
                    f.write(f"{i}. **{component}**: è´¡çŒ® {contribution:.1f}% (ç§»é™¤åæ€§èƒ½ä¸‹é™)\\n")
                
                f.write("\\n")
            
            f.write("### ä¸»è¦å‘ç°\\n\\n")
            f.write("1. **ç³»ç»Ÿå®Œæ•´æ€§**: æ¯ä¸ªç»„ä»¶éƒ½å¯¹æ•´ä½“æ€§èƒ½æœ‰é‡è¦è´¡çŒ®\\n")
            f.write("2. **ç»„ä»¶ååŒ**: å¤šä¸ªåˆ›æ–°ç»„ä»¶ååŒå·¥ä½œï¼Œäº§ç”Ÿæœ€ä½³æ•ˆæœ\\n")
            f.write("3. **è®¾è®¡éªŒè¯**: æ¶ˆèå®éªŒéªŒè¯äº†æˆ‘ä»¬çš„ç³»ç»Ÿè®¾è®¡çš„æœ‰æ•ˆæ€§\\n\\n")
            
            f.write("---\\n")
            f.write("*æŠ¥å‘Šç”±æ¶ˆèå®éªŒç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\\n")
    
    def quick_test(self):
        """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ¶ˆèå®éªŒï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        print("   è®­ç»ƒæ­¥æ•°: 1,000")
        print("   è¯„ä¼°å›åˆ: 3")
        print("=" * 40)
        
        return self.run_all_experiments(timesteps=1000, eval_episodes=3)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¶ˆèå®éªŒè¿è¡Œå™¨")
    parser.add_argument('--experiment', type=str, choices=[
        'full_system', 'no_high_priority', 'single_objective', 
        'traditional_pyramid', 'no_transfer', 'all'
    ], default='all', help='è¦è¿è¡Œçš„æ¶ˆèå®éªŒç±»å‹')
    
    parser.add_argument('--timesteps', type=int, default=100000, 
                       help='è®­ç»ƒæ­¥æ•° (é»˜è®¤: 100,000)')
    parser.add_argument('--eval-episodes', type=int, default=30,
                       help='è¯„ä¼°å›åˆæ•° (é»˜è®¤: 30)')
    parser.add_argument('--output-dir', type=str, default='./ablation_results/',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: ./ablation_results/)')
    parser.add_argument('--quick-test', action='store_true',
                       help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (1kæ­¥æ•°, 3å›åˆ)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒè¿è¡Œå™¨
    runner = AblationExperimentRunner(output_dir=args.output_dir)
    
    print("ğŸ§ª æ¶ˆèå®éªŒç ”ç©¶ç³»ç»Ÿ")
    print("=" * 50)
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    if args.quick_test:
        # å¿«é€Ÿæµ‹è¯•
        results = runner.quick_test()
    elif args.experiment == 'all':
        # è¿è¡Œæ‰€æœ‰å®éªŒ
        results = runner.run_all_experiments(args.timesteps, args.eval_episodes)
    else:
        # è¿è¡Œå•ä¸ªå®éªŒ
        result = runner.run_single_experiment(args.experiment, args.timesteps, args.eval_episodes)
        results = {args.experiment: result}
    
    print(f"\\nğŸ‰ å®éªŒå®Œæˆ! ç»“æœä¿å­˜è‡³: {args.output_dir}")
    
    return results


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\\n\\nâš ï¸  å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\\n\\nâŒ å®éªŒæ‰§è¡Œå‡ºé”™: {str(e)}")
        sys.exit(1)