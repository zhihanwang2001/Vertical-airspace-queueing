"""
å®éªŒA: 5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯”å®éªŒ (CRITICAL)
Experiment A: Structural Comparison at 5Ã— Load (CRITICAL)

é—®é¢˜èƒŒæ™¯ï¼š
- è¡¥å……å®éªŒ(n=3) @ 10Ã—è´Ÿè½½å…¨éƒ¨å´©æºƒ (crash_rate=100%)
- åŸå› : 10Ã—è´Ÿè½½è¿‡äºæç«¯ï¼Œå€’é‡‘å­—å¡”åº•å±‚ Ï=345%ï¼ŒDRLæ— æ³•å­¦ä¹ æœ‰æ•ˆç­–ç•¥
- å½±å“: æ— æ³•éªŒè¯"å€’é‡‘å­—å¡”ä¼˜äºæ­£é‡‘å­—å¡”"çš„æ ¸å¿ƒclaim

è§£å†³æ–¹æ¡ˆï¼š
- é™ä½è´Ÿè½½è‡³5Ã—å€ (Ïâ‰ˆ172% - å…·æœ‰æŒ‘æˆ˜æ€§ä½†å¯å­¦ä¹ )
- åªè¿è¡Œç»“æ„å¯¹æ¯”å®éªŒ (ä¸å«å®¹é‡æ‚–è®º)
- ä¿æŒå…¶ä»–å‚æ•°ä¸åŸå®éªŒä¸€è‡´

å®éªŒè®¾è®¡ï¼š
- Config 1: Inverted Pyramid [8,6,4,3,2] @ 5Ã— load
- Config 2: Normal Pyramid [2,3,4,6,8] @ 5Ã— load
- Algorithms: A2C, PPO
- Seeds: 42 (existing), 123, 456 (new)

é»˜è®¤æ€»è®¡: 12 training runsï¼ˆå¯é€šè¿‡ --seeds / --n-seeds æ‰©å±•ï¼‰
- 2 configs Ã— 2 algorithms Ã— N seeds

é¢„æœŸç»“æœï¼š
- å€’é‡‘å­—å¡”åº”æ˜¾è‘—ä¼˜äºæ­£é‡‘å­—å¡”
- Crash rate < 50% (å¯æ¥å—çš„è®­ç»ƒç¨³å®šæ€§)
- æä¾›n=3ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
"""

import sys
import os
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import gymnasium as gym
import numpy as np
import json
import time
from datetime import datetime
from stable_baselines3 import A2C, PPO

from env.config import VerticalQueueConfig
from env.configurable_env_wrapper import ConfigurableEnvWrapper
from env.drl_wrapper_fixed import DictToBoxActionWrapperFixed, ObservationWrapperFixed


def create_config(config_type='inverted_pyramid', high_load_multiplier=5.0):
    """
    åˆ›å»ºé«˜è´Ÿè½½é…ç½®

    config_type: é…ç½®ç±»å‹
    - inverted_pyramid: [8,6,4,3,2] å€’é‡‘å­—å¡”
    - normal_pyramid: [2,3,4,6,8] æ­£é‡‘å­—å¡”
    - low_capacity: [2,2,2,2,2] K=10
    - capacity_30: [6,6,6,6,6] K=30
    """
    config = VerticalQueueConfig()

    # è®¾ç½®å®¹é‡
    if config_type == 'inverted_pyramid':
        config.layer_capacities = [8, 6, 4, 3, 2]  # æ€»23
    elif config_type == 'normal_pyramid':
        config.layer_capacities = [2, 3, 4, 6, 8]  # æ€»23
    elif config_type == 'low_capacity':
        config.layer_capacities = [2, 2, 2, 2, 2]  # æ€»10 (K=10)
    elif config_type == 'capacity_30':
        config.layer_capacities = [6, 6, 6, 6, 6]  # æ€»30 (K=30)
    else:
        raise ValueError(f"Unknown config type: {config_type}")

    # å›ºå®šçœŸå®UAMæµé‡æ¨¡å¼
    config.arrival_weights = [0.3, 0.25, 0.2, 0.15, 0.1]

    # é«˜è´Ÿè½½è®¾ç½® (5x - é™ä½è‡ª10xä»¥æ”¹å–„è®­ç»ƒç¨³å®šæ€§)
    total_capacity = sum(config.layer_capacities)
    avg_service_rate = np.mean(config.layer_service_rates)
    base_rate_v3 = 0.75 * total_capacity * avg_service_rate / 5
    config.base_arrival_rate = base_rate_v3 * high_load_multiplier  # é»˜è®¤5.0Ã—

    # è®¡ç®—æ¯å±‚çš„ç†è®ºè´Ÿè½½
    layer_loads = []
    for i, (w, c) in enumerate(zip(config.arrival_weights, config.layer_capacities)):
        layer_arrival = config.base_arrival_rate * w
        actual_service_rate = config.layer_service_rates[i]
        layer_load = layer_arrival / (c * actual_service_rate)
        layer_loads.append(layer_load)

    print(f"\n{'='*80}")
    print(f"é…ç½®: {config_type}")
    print(f"å®¹é‡: {config.layer_capacities} (æ€»è®¡: {total_capacity})")
    print(f"åˆ°è¾¾æƒé‡: {config.arrival_weights}")
    print(f"æ€»åˆ°è¾¾ç‡: {config.base_arrival_rate:.2f} ({high_load_multiplier:.1f}xé«˜è´Ÿè½½)")
    print(f"å¹³å‡è´Ÿè½½: {np.mean(layer_loads)*100:.1f}%")
    print(f"{'='*80}\n")

    return config


def create_wrapped_env(config):
    """åˆ›å»ºåŒ…è£…åçš„ç¯å¢ƒ"""
    base_env = ConfigurableEnvWrapper(config=config)
    wrapped_env = DictToBoxActionWrapperFixed(base_env)
    wrapped_env = ObservationWrapperFixed(wrapped_env)
    return wrapped_env


def train_and_evaluate(algorithm_name='A2C', config_type='inverted_pyramid',
                       timesteps=100000, eval_episodes=50, seed=42,
                       high_load_multiplier=5.0):
    """
    è®­ç»ƒå’Œè¯„ä¼°å•æ¬¡å®éªŒ @ 5Ã— è´Ÿè½½

    å‚æ•°:
    - algorithm_name: 'A2C' or 'PPO'
    - config_type: é…ç½®ç±»å‹ (inverted_pyramid æˆ– normal_pyramid)
    - timesteps: è®­ç»ƒæ­¥æ•° (é»˜è®¤100K)
    - eval_episodes: è¯„ä¼°å›åˆæ•° (é»˜è®¤50)
    - seed: éšæœºç§å­
    - high_load_multiplier: é«˜è´Ÿè½½å€æ•° (é»˜è®¤5x - é™ä½è‡ª10x)
    """

    print(f"\n{'='*80}")
    print(f"å®éªŒ: {algorithm_name} + {config_type}")
    print(f"Seed: {seed}")
    print(f"{'='*80}\n")

    config = create_config(config_type, high_load_multiplier)
    env = create_wrapped_env(config)

    # ä¿å­˜è·¯å¾„: Data/ablation_studies/structural_5x_load/{config_type}/{algorithm}_{seed}_results.json
    save_dir = Path(project_root).parent / 'Data' / 'ablation_studies' / 'structural_5x_load' / config_type
    save_dir.mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    # åˆ›å»ºæ¨¡å‹
    if algorithm_name == 'A2C':
        model = A2C('MlpPolicy', env, learning_rate=0.0007, n_steps=32,
                   gamma=0.99, gae_lambda=0.95, ent_coef=0.01, vf_coef=0.5,
                   max_grad_norm=0.5, normalize_advantage=True,
                   verbose=1, seed=seed, device='cuda')
    elif algorithm_name == 'PPO':
        model = PPO('MlpPolicy', env, learning_rate=0.0003, n_steps=2048,
                   batch_size=64, n_epochs=10, gamma=0.99, gae_lambda=0.95,
                   clip_range=0.2, ent_coef=0.0, vf_coef=0.5,
                   max_grad_norm=0.5, verbose=1, seed=seed, device='cuda')
    else:
        raise ValueError(f"Unknown algorithm: {algorithm_name}")

    print(f"\nå¼€å§‹è®­ç»ƒ ({timesteps} timesteps)...")
    model.learn(total_timesteps=timesteps)
    training_time = time.time() - start_time

    # ä¿å­˜æ¨¡å‹
    model_path = save_dir / f'{algorithm_name}_seed{seed}_model.zip'
    model.save(str(model_path))

    # è¯„ä¼°
    print(f"\nè¯„ä¼° ({eval_episodes} å›åˆ)...")
    eval_rewards = []
    eval_lengths = []
    eval_terminated_count = 0  # çœŸå®å´©æºƒ
    eval_truncated_count = 0   # æ­£å¸¸æˆªæ–­
    eval_waiting_times = []
    eval_utilizations = []
    # ç¨³å®šæ€§ä»£ç†æŒ‡æ ‡ï¼ˆæ¯ä¸ªepisodeçš„å‡å€¼ï¼‰
    ep_means_lyapunov = []
    ep_means_lyapunov_drift = []
    ep_means_drift_l1 = []
    ep_safe_ratios = []
    ep_means_max_load = []

    for ep in range(eval_episodes):
        obs, info = env.reset()
        done = False
        ep_reward = 0
        ep_len = 0
        ep_waiting = []
        ep_utils = []
        episode_terminated = False
        episode_truncated = False

        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, term, trunc, info = env.step(action)
            done = term or trunc
            ep_reward += reward
            ep_len += 1

            if done:
                episode_terminated = term
                episode_truncated = trunc

            if 'avg_waiting_time' in info:
                ep_waiting.append(info['avg_waiting_time'])
            if 'utilization_rates' in info:
                ep_utils.append(np.mean(info['utilization_rates']))
            # æ”¶é›†ç¨³å®šæ€§ä»£ç†æŒ‡æ ‡
            if isinstance(info, dict):
                if 'lyapunov' in info:
                    ep_means_lyapunov.append(info['lyapunov'])
                if 'lyapunov_drift' in info:
                    ep_means_lyapunov_drift.append(info['lyapunov_drift'])
                if 'drift_l1' in info:
                    ep_means_drift_l1.append(info['drift_l1'])
                if 'is_safe' in info:
                    # ä»¥å¸ƒå°”å€¼å¹³å‡ä½œä¸ºå®‰å…¨æ¯”ä¾‹è´¡çŒ®
                    ep_safe_ratios.append(1.0 if info['is_safe'] else 0.0)
                if 'max_load_rate' in info:
                    ep_means_max_load.append(info['max_load_rate'])

        eval_rewards.append(ep_reward)
        eval_lengths.append(ep_len)

        if episode_terminated:
            eval_terminated_count += 1
            crash_marker = " ğŸ”´[CRASHED]"
        elif episode_truncated:
            eval_truncated_count += 1
            crash_marker = " âœ…[å®Œæˆ]"
        else:
            crash_marker = ""

        if ep_waiting:
            eval_waiting_times.append(np.mean(ep_waiting))
        if ep_utils:
            eval_utilizations.append(np.mean(ep_utils))

        if (ep + 1) % 10 == 0:
            print(f"  Episode {ep+1}: {ep_reward:.2f} (é•¿åº¦{ep_len}){crash_marker}")

    # ç»Ÿè®¡ç»“æœ
    mean_reward = np.mean(eval_rewards)
    std_reward = np.std(eval_rewards)
    terminated_rate = eval_terminated_count / eval_episodes
    truncated_rate = eval_truncated_count / eval_episodes
    mean_waiting = np.mean(eval_waiting_times) if eval_waiting_times else 0
    mean_util = np.mean(eval_utilizations) if eval_utilizations else 0
    mean_length = np.mean(eval_lengths)

    # è®¡ç®—ç¨³å®šæ€§ä»£ç†çš„å‡å€¼ï¼ˆè‹¥å­˜åœ¨ï¼‰
    def _safe_mean(arr):
        return float(np.mean(arr)) if len(arr) > 0 else 0.0
    stability_metrics = {
        'mean_lyapunov': _safe_mean(ep_means_lyapunov),
        'mean_lyapunov_drift': _safe_mean(ep_means_lyapunov_drift),
        'mean_drift_l1': _safe_mean(ep_means_drift_l1),
        'mean_safe_ratio': _safe_mean(ep_safe_ratios),
        'mean_max_load_rate': _safe_mean(ep_means_max_load)
    }

    print(f"\n{'='*80}")
    print(f"è¯„ä¼°ç»“æœ:")
    print(f"  å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    print(f"  æœ€ä½³å¥–åŠ±: {np.max(eval_rewards):.2f}")
    print(f"  ğŸ”´ å´©æºƒç‡: {terminated_rate*100:.1f}% ({eval_terminated_count}/{eval_episodes})")
    print(f"  âœ… å®Œæˆç‡: {truncated_rate*100:.1f}% ({eval_truncated_count}/{eval_episodes})")
    print(f"  å¹³å‡å›åˆé•¿åº¦: {mean_length:.1f}")
    print(f"  è®­ç»ƒæ—¶é—´: {training_time/60:.2f}åˆ†é’Ÿ")
    print(f"{'='*80}")

    # ä¿å­˜ç»“æœ
    results = {
        'config_type': config_type,
        'algorithm': algorithm_name,
        'seed': seed,
        'layer_capacities': config.layer_capacities,
        'total_capacity': sum(config.layer_capacities),
        'arrival_weights': config.arrival_weights,
        'base_arrival_rate': float(config.base_arrival_rate),
        'high_load_multiplier': high_load_multiplier,
        'mean_reward': float(mean_reward),
        'std_reward': float(std_reward),
        'best_reward': float(np.max(eval_rewards)),
        'worst_reward': float(np.min(eval_rewards)),
        'crash_rate': float(terminated_rate),
        'completion_rate': float(truncated_rate),
        'terminated_count': eval_terminated_count,
        'truncated_count': eval_truncated_count,
        'mean_episode_length': float(mean_length),
        'mean_waiting_time': float(mean_waiting),
        'mean_utilization': float(mean_util),
        'training_time_minutes': float(training_time / 60),
        'eval_rewards': [float(r) for r in eval_rewards],
        'eval_lengths': [int(l) for l in eval_lengths],
        'timestamp': datetime.now().isoformat()
    }
    results.update(stability_metrics)

    results_path = save_dir / f'{algorithm_name}_seed{seed}_results.json'
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {results_path}\n")

    env.close()
    return results


def _parse_seeds(seeds_arg: str = None, n_seeds: int = None) -> list:
    """Parse seeds from CLI: comma-separated list or generate range starting at 42."""
    if seeds_arg:
        try:
            return [int(s.strip()) for s in seeds_arg.split(',') if s.strip()]
        except Exception:
            print(f"âš ï¸ æ— æ³•è§£æ --seeds={seeds_arg}ï¼Œä½¿ç”¨é»˜è®¤ [42,123,456]")
            return [42, 123, 456]
    if n_seeds and n_seeds > 0:
        return list(range(42, 42 + n_seeds))
    return [42, 123, 456]


def run_all_supplementary_experiments(seeds: list = None,
                                      timesteps: int = 100000,
                                      eval_episodes: int = 50,
                                      high_load_multiplier: float = 5.0):
    """
    è¿è¡Œå®éªŒA: 5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯” (12 runs)

    ç›®æ ‡: ä¿®å¤10Ã—è´Ÿè½½ä¸‹çš„100%å´©æºƒé—®é¢˜

    å®éªŒçŸ©é˜µ:
    - Inverted Pyramid [8,6,4,3,2] vs Normal Pyramid [2,3,4,6,8]
    - Algorithms: A2C, PPO
    - Seeds: 42 (existing baseline), 123, 456 (new runs for n=3)
    - Load: 5Ã— (é™ä½è‡ª10Ã—ä»¥æ”¹å–„è®­ç»ƒç¨³å®šæ€§)
    """

    # å®šä¹‰å®éªŒçŸ©é˜µ - åªå«ç»“æ„å¯¹æ¯”
    if seeds is None:
        seeds = [42, 123, 456]

    experiments = [
        {'config': 'inverted_pyramid', 'algo': 'A2C', 'seeds': seeds},
        {'config': 'inverted_pyramid', 'algo': 'PPO', 'seeds': seeds},
        {'config': 'normal_pyramid', 'algo': 'A2C', 'seeds': seeds},
        {'config': 'normal_pyramid', 'algo': 'PPO', 'seeds': seeds},
    ]

    total_experiments = sum(len(exp['seeds']) for exp in experiments)
    print(f"\n{'='*80}")
    print(f"å®éªŒA: 5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯”")
    print(f"æ€»è®¡: {total_experiments} æ¬¡è®­ç»ƒ (2 configs Ã— 2 algos Ã— 3 seeds)")
    print(f"è´Ÿè½½å€æ•°: 5Ã— (é™ä½è‡ª10Ã—ä»¥æ”¹å–„è®­ç»ƒç¨³å®šæ€§)")
    print(f"{'='*80}")

    # è¿è¡Œå®éªŒ
    all_results = []
    completed = 0

    for exp_config in experiments:
        config_type = exp_config['config']
        algorithm = exp_config['algo']
        seeds = exp_config['seeds']

        for seed in seeds:
            completed += 1
            print(f"\n\n{'#'*80}")
            print(f"è¿›åº¦: [{completed}/{total_experiments}] {config_type} + {algorithm} (seed={seed})")
            print(f"{'#'*80}")

            try:
                result = train_and_evaluate(
                    algorithm_name=algorithm,
                    config_type=config_type,
                    timesteps=timesteps,
                    eval_episodes=eval_episodes,
                    seed=seed,
                    high_load_multiplier=high_load_multiplier
                )
                all_results.append(result)
                print(f"\nâœ… [{completed}/{total_experiments}] å®Œæˆ: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}")

            except Exception as e:
                print(f"\nâŒ [{completed}/{total_experiments}] å¤±è´¥: {config_type} + {algorithm} (seed={seed})")
                print(f"é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

    # ä¿å­˜æ€»ç»“
    summary = {
        'total_experiments': total_experiments,
        'completed': len(all_results),
        'failed': total_experiments - len(all_results),
        'timestamp': datetime.now().isoformat(),
        'experiments': all_results
    }

    summary_path = Path(project_root).parent / 'Data' / 'ablation_studies' / 'structural_5x_load' / 'EXPERIMENT_SUMMARY.json'
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)

    print(f"\n\n{'='*80}")
    print(f"å®éªŒAå®Œæˆ! (5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯”)")
    print(f"æˆåŠŸ: {len(all_results)}/{total_experiments}")
    print(f"æ€»ç»“å·²ä¿å­˜è‡³: {summary_path}")
    print(f"{'='*80}\n")

    # æ˜¾ç¤ºå…³é”®ç»“æœå¯¹æ¯”
    if len(all_results) > 0:
        print("\nå…³é”®ç»“æœé¢„è§ˆ:")
        print("="*80)
        for r in all_results:
            crash_indicator = "ğŸ”´" if r['crash_rate'] > 0.5 else "âœ…"
            print(f"{crash_indicator} {r['config_type']:<20} {r['algorithm']:<5} seed={r['seed']:<4} "
                  f"reward={r['mean_reward']:>8.1f} crash={r['crash_rate']*100:>5.1f}%")
        print("="*80)

    return all_results


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='å®éªŒA: 5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯”')
    parser.add_argument('--mode', choices=['single', 'all'], default='all',
                       help='è¿è¡Œæ¨¡å¼: single (å•æ¬¡å®éªŒ) æˆ– all (å…¨éƒ¨12æ¬¡)')
    parser.add_argument('--algorithm', choices=['A2C', 'PPO'],
                       help='ç®—æ³• (ä»…singleæ¨¡å¼)')
    parser.add_argument('--config',
                       choices=['inverted_pyramid', 'normal_pyramid', 'low_capacity', 'capacity_30'],
                       help='é…ç½®ç±»å‹ (ä»…singleæ¨¡å¼)')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ (ä»…singleæ¨¡å¼, é»˜è®¤42)')
    parser.add_argument('--timesteps', type=int, default=100000,
                       help='è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--eval-episodes', type=int, default=50,
                       help='è¯„ä¼°å›åˆæ•°')
    parser.add_argument('--load-multiplier', type=float, default=5.0,
                       help='è´Ÿè½½å€æ•° (é»˜è®¤5.0)')
    parser.add_argument('--seeds', type=str, default=None,
                       help='ä»¥é€—å·åˆ†éš”çš„éšæœºç§å­åˆ—è¡¨ï¼Œå¦‚ 42,123,456')
    parser.add_argument('--n-seeds', type=int, default=None,
                       help='è‡ªåŠ¨ç”Ÿæˆçš„ç§å­æ•°é‡ï¼ˆä»42å¼€å§‹é€’å¢ï¼‰')

    args = parser.parse_args()

    if args.mode == 'all':
        seeds = _parse_seeds(args.seeds, args.n_seeds)
        print(f"\nğŸš€ å¼€å§‹è¿è¡Œå®éªŒA: 5Ã— è´Ÿè½½ç»“æ„å¯¹æ¯” ({len(seeds)*4} æ¬¡è®­ç»ƒ)...\n")
        run_all_supplementary_experiments(
            seeds=seeds,
            timesteps=args.timesteps,
            eval_episodes=args.eval_episodes,
            high_load_multiplier=args.load_multiplier
        )

    elif args.mode == 'single':
        if not args.algorithm or not args.config:
            print("âŒ é”™è¯¯: singleæ¨¡å¼éœ€è¦æŒ‡å®š --algorithm å’Œ --config")
            parser.print_help()
        else:
            print(f"\nğŸš€ è¿è¡Œå•æ¬¡å®éªŒ: {args.algorithm} + {args.config} (seed={args.seed}) @ {args.load_multiplier}Ã— load\n")
            result = train_and_evaluate(
                algorithm_name=args.algorithm,
                config_type=args.config,
                timesteps=args.timesteps,
                eval_episodes=args.eval_episodes,
                seed=args.seed,
                high_load_multiplier=args.load_multiplier
            )
            print(f"\nâœ… å®Œæˆ: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}, crash={result['crash_rate']*100:.1f}%")
