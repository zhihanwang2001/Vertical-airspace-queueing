% ============================================================
% References for Deep RL Vertical Queueing Systems Paper
% Based on 28 analyzed papers in Documentation/references/
% Created: 2026-01-05
% ============================================================

% ============================================================
% T-Series: Queueing Theory and Scheduling
% ============================================================

@article{amjath2024queueing,
  title={Queueing network models for the analysis and optimisation of material handling systems: a systematic literature review},
  author={Amjath, M. and Kerbache, L. and Elomri, A. and others},
  journal={Flexible Services and Manufacturing Journal},
  volume={36},
  pages={668--709},
  year={2024},
  publisher={Springer},
  doi={10.1007/s10696-023-09505-x}
}

@article{efrosinin2023optimal,
  title={Optimal Scheduling in General Multi-Queue System by Combining Simulation and Neural Network Techniques},
  author={Efrosinin, Dmitry and Vishnevsky, Vladimir and Stepanova, Natalia},
  journal={Sensors},
  volume={23},
  number={12},
  pages={5479},
  year={2023},
  publisher={MDPI},
  doi={10.3390/s23125479}
}

@article{choi2020state,
  title={Analysis of the State-Dependent Queueing Model and Its Application to Battery Swapping and Charging Stations},
  author={Choi, D. I. and Lim, D.-E.},
  journal={Sustainability},
  volume={12},
  number={6},
  pages={2343},
  year={2020},
  publisher={MDPI},
  doi={10.3390/su12062343}
}

% ============================================================
% A-Series: Deep Reinforcement Learning Algorithms
% ============================================================

@inproceedings{fujimoto2023sale,
  title={For SALE: State-Action Representation Learning for Deep Reinforcement Learning},
  author={Fujimoto, Scott and Chang, Wei-Di and Smith, Edward J. and Gu, Shixiang Shane and Precup, Doina and Meger, David},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

@inproceedings{espeholt2018impala,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}

@inproceedings{kapturowski2019r2d2,
  title={Recurrent Experience Replay in Distributed Reinforcement Learning},
  author={Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

% ============================================================
% U-Series: UAM and Airspace Management
% ============================================================

@article{pongsakornsathien2025laam,
  title={Advances in low-altitude airspace management for uncrewed aircraft and advanced air mobility},
  author={Pongsakornsathien, N. and El-Din Safwat, N. and Xie, Y. and Gardi, A. and Sabatini, R.},
  journal={Progress in Aerospace Sciences},
  volume={154},
  pages={101085},
  year={2025},
  publisher={Elsevier},
  doi={10.1016/j.paerosci.2025.101085}
}

@article{stuive2024airspace,
  title={Airspace network design for urban UAV traffic management with congestion},
  author={Stuive, L. and Gzara, F.},
  journal={Transportation Research Part C: Emerging Technologies},
  volume={169},
  pages={104882},
  year={2024},
  publisher={Elsevier},
  doi={10.1016/j.trc.2024.104882}
}

@article{xie2024hybrid,
  title={Hybrid AI-based 4D trajectory management system for dense low altitude operations and Urban Air Mobility},
  author={Xie, Y. and Gardi, A. and Liang, M. and Sabatini, R.},
  journal={Aerospace Science and Technology},
  volume={153},
  pages={109422},
  year={2024},
  publisher={Elsevier},
  doi={10.1016/j.ast.2024.109422}
}

@article{paul2025datadriven,
  title={Data-driven optimization for drone delivery service planning with online demand},
  author={Paul, A. and Levin, M. W. and Waller, S. T. and Rey, D.},
  journal={Transportation Research Part E: Logistics and Transportation Review},
  volume={198},
  pages={104095},
  year={2025},
  publisher={Elsevier},
  doi={10.1016/j.tre.2025.104095}
}

@article{kong2024multiuav,
  title={Multi-UAV simultaneous target assignment and path planning based on deep reinforcement learning in dynamic multiple obstacles environments},
  author={Kong, X. and Zhou, Y. and Li, Z. and Wang, S.},
  journal={Frontiers in Neurorobotics},
  volume={17},
  year={2024},
  publisher={Frontiers},
  doi={10.3389/fnbot.2023.1302898}
}

@article{liu2024multiuav,
  title={Reinforcement-Learning-Based Multi-UAV Cooperative Search for Moving Targets in 3D Scenarios},
  author={Liu, Y. and Li, X. and Wang, J. and Wei, F. and Yang, J.},
  journal={Drones},
  volume={8},
  number={8},
  pages={378},
  year={2024},
  publisher={MDPI},
  doi={10.3390/drones8080378}
}

@article{zhang2025uav,
  title={Autonomous decision-making of UAV cluster with communication constraints based on reinforcement learning},
  author={Zhang, T.-T. and Chen, Y. and Dong, R.-z. and others},
  journal={Journal of Cloud Computing},
  volume={14},
  pages={12},
  year={2025},
  publisher={Springer},
  doi={10.1186/s13677-025-00738-9}
}

% ============================================================
% S-Series: System Optimization and Scheduling
% ============================================================

@article{wang2024order,
  title={Reinforcement Learning-Based Dynamic Order Recommendation for On-Demand Food Delivery},
  author={Wang, X. and Wang, L. and Dong, C. and Ren, H. and Xing, K.},
  journal={Tsinghua Science and Technology},
  volume={29},
  number={2},
  pages={356--367},
  year={2024},
  publisher={TUP},
  doi={10.26599/TST.2023.9010041}
}

@article{wang2023online,
  title={An Online Deep Reinforcement Learning-Based Order Recommendation Framework for Rider-Centered Food Delivery System},
  author={Wang, X. and Wang, L. and Dong, C. and Ren, H. and Xing, K.},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={24},
  number={5},
  pages={5640--5654},
  year={2023},
  publisher={IEEE},
  doi={10.1109/TITS.2023.3237580}
}

@article{jahanshahi2022meal,
  title={A deep reinforcement learning approach for the meal delivery problem},
  author={Jahanshahi, H. and Bozanta, A. and Cevik, M. and Kavuk, E. M. and Tosun, A. and Sonuc, S. B. and Kosucu, B. and Ba≈üar, A.},
  journal={Knowledge-Based Systems},
  volume={243},
  pages={108489},
  year={2022},
  publisher={Elsevier},
  doi={10.1016/j.knosys.2022.108489}
}

@article{li2024fairness,
  title={Fairness-aware task offloading and load balancing with delay constraints for Power Internet of Things},
  author={Li, Xue and Chen, Xiaojuan and Li, Guohua},
  journal={Ad Hoc Networks},
  volume={153},
  pages={103333},
  year={2024},
  publisher={Elsevier},
  doi={10.1016/j.adhoc.2023.103333}
}

@article{chen2024wfq,
  title={Enhancing Fairness for Approximate Weighted Fair Queueing With a Single Queue},
  author={Chen, W. and Tian, Y. and Yu, X. and Zheng, B. and Zhang, X.},
  journal={IEEE/ACM Transactions on Networking},
  volume={32},
  number={5},
  pages={3901--3915},
  year={2024},
  publisher={IEEE},
  doi={10.1109/TNET.2024.3399212}
}

@inproceedings{do2022gini,
  title={Optimizing Generalized Gini Indices for Fairness in Rankings},
  author={Do, Virginie and Usunier, Nicolas},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2022},
  organization={ACM}
}

% ============================================================
% Additional References (Classic RL and Statistics)
% ============================================================

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S. and Barto, Andrew G.},
  year={2018},
  publisher={MIT Press},
  edition={2nd}
}

@article{schulman2017proximal,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous Methods for Deep Reinforcement Learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@book{cohen1988statistical,
  title={Statistical Power Analysis for the Behavioral Sciences},
  author={Cohen, Jacob},
  year={1988},
  publisher={Lawrence Erlbaum Associates},
  edition={2nd}
}

% ============================================================
% End of References
% ============================================================
